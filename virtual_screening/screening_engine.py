# /Boltz-WebUI/virtual_screening/screening_engine.py

"""
screening_engine_simplified.py

è™šæ‹Ÿç­›é€‰å¼•æ“ï¼š
1. ScreeningEngine: ä¸»è¦ç­›é€‰é€»è¾‘æ§åˆ¶å™¨
2. ScoringSystem: è¯„åˆ†ç³»ç»Ÿ  
3. BatchManager: æ‰¹é‡ä½œä¸šç®¡ç†
4. ResultProcessor: ç»“æœå¤„ç†å™¨
"""

import os
import yaml
import time
import json
import shutil
import logging
import tempfile
import concurrent.futures
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from pathlib import Path
import pandas as pd
import numpy as np

from api_client import BoltzApiClient
from molecule_library import MoleculeLibrary, Molecule, LibraryProcessor
from affinity_calculator import SmallMoleculeAffinityEnhancer
from html_reporter import HTMLReporter

logger = logging.getLogger(__name__)

@dataclass
class ScreeningResult:
    """ç­›é€‰ç»“æœæ•°æ®ç±»"""
    molecule_id: str
    molecule_name: str
    sequence: str
    mol_type: str
    binding_score: float
    confidence_score: float
    structural_score: float
    combined_score: float
    rank: int = 0
    properties: Dict[str, Any] = None
    structure_path: str = ""
    
    def __post_init__(self):
        if self.properties is None:
            self.properties = {}

@dataclass
class ScreeningConfig:
    """ç­›é€‰é…ç½®å‚æ•°"""
    # åŸºæœ¬å‚æ•°
    target_yaml: str
    library_path: str
    library_type: str
    output_dir: str
    
    # ç­›é€‰å‚æ•°
    max_molecules: int = -1  # -1è¡¨ç¤ºå…¨éƒ¨
    batch_size: int = 50
    max_workers: int = 4
    timeout: int = 1800
    retry_attempts: int = 3
    
    # è¯„åˆ†å‚æ•°
    scoring_weights: Dict[str, float] = None
    min_binding_score: float = 0.0
    top_n: int = 100
    
    # é«˜çº§å‚æ•°
    use_msa_server: bool = False
    save_structures: bool = True
    generate_plots: bool = True
    
    # æ–°å¢ï¼šäº²å’ŒåŠ›è®¡ç®—å‚æ•°
    auto_enable_affinity: bool = True  # è‡ªåŠ¨å¯ç”¨äº²å’ŒåŠ›è®¡ç®—
    enable_affinity: bool = False
    target_sequence: str = ""
    
    def __post_init__(self):
        if self.scoring_weights is None:
            self.scoring_weights = {
                "binding_affinity": 0.6,
                "structural_stability": 0.2,
                "confidence": 0.2
            }

class ScoringSystem:
    """è¯„åˆ†ç³»ç»Ÿ"""
    
    def __init__(self, weights: Dict[str, float] = None):
        self.weights = weights or {
            "binding_affinity": 0.6,
            "structural_stability": 0.2,
            "confidence": 0.2
        }
    
    def calculate_binding_score(self, metrics: Dict[str, Any]) -> float:
        """è®¡ç®—ç»“åˆäº²å’ŒåŠ›è¯„åˆ†"""
        # åŸºäºipTMåˆ†æ•°è®¡ç®—ç»“åˆäº²å’ŒåŠ›
        iptm = metrics.get('iptm', 0.0)
        return float(iptm)
    
    def calculate_structural_score(self, metrics: Dict[str, Any]) -> float:
        """è®¡ç®—ç»“æ„ç¨³å®šæ€§è¯„åˆ†"""
        # åŸºäºpLDDTåˆ†æ•°è®¡ç®—ç»“æ„ç¨³å®šæ€§
        plddt = metrics.get('plddt', 0.0)
        
        # pLDDTå€¼é€šå¸¸åœ¨0-1èŒƒå›´å†…ï¼ˆå·²ç»æ˜¯å½’ä¸€åŒ–çš„ï¼‰ï¼Œä¸éœ€è¦é™¤ä»¥100
        # å¦‚æœpLDDTå€¼å¤§äº1ï¼Œè¯´æ˜æ˜¯0-100èŒƒå›´çš„ï¼Œéœ€è¦å½’ä¸€åŒ–
        if plddt > 1.0:
            return float(plddt) / 100.0
        else:
            return float(plddt)  # å·²ç»æ˜¯0-1èŒƒå›´
    
    def calculate_confidence_score(self, metrics: Dict[str, Any]) -> float:
        """è®¡ç®—é¢„æµ‹ç½®ä¿¡åº¦è¯„åˆ†"""
        # ç»¼åˆå¤šä¸ªç½®ä¿¡åº¦æŒ‡æ ‡
        confidence_scores = []
        
        if 'plddt' in metrics:
            confidence_scores.append(metrics['plddt'] / 100.0)
        
        if 'ptm' in metrics:
            confidence_scores.append(metrics['ptm'])
        
        if 'iptm' in metrics:
            confidence_scores.append(metrics['iptm'])
        
        return float(np.mean(confidence_scores)) if confidence_scores else 0.0
    
    def calculate_combined_score(self, binding_score: float, structural_score: float, 
                               confidence_score: float) -> float:
        """è®¡ç®—ç»¼åˆè¯„åˆ†"""
        combined = (
            binding_score * self.weights.get("binding_affinity", 0.6) +
            structural_score * self.weights.get("structural_stability", 0.2) +
            confidence_score * self.weights.get("confidence", 0.2)
        )
        return float(combined)
    
    def score_molecule(self, molecule: Molecule, prediction_results: Dict[str, Any]) -> ScreeningResult:
        """ä¸ºå•ä¸ªåˆ†å­è®¡ç®—æ‰€æœ‰è¯„åˆ†"""
        # è§£æé¢„æµ‹ç»“æœä¸­çš„æŒ‡æ ‡
        metrics = self._parse_prediction_metrics(prediction_results)
        
        # è®¡ç®—å„é¡¹è¯„åˆ†
        binding_score = self.calculate_binding_score(metrics)
        structural_score = self.calculate_structural_score(metrics)
        confidence_score = self.calculate_confidence_score(metrics)
        combined_score = self.calculate_combined_score(binding_score, structural_score, confidence_score)
        
        # åˆ›å»ºç­›é€‰ç»“æœ
        result = ScreeningResult(
            molecule_id=molecule.id,
            molecule_name=molecule.name,
            sequence=molecule.sequence,
            mol_type=molecule.mol_type,
            binding_score=binding_score,
            confidence_score=confidence_score,
            structural_score=structural_score,
            combined_score=combined_score,
            properties=molecule.properties.copy()
        )
        
        # æ·»åŠ é¢„æµ‹æŒ‡æ ‡åˆ°å±æ€§ä¸­
        result.properties.update(metrics)
        
        return result
    
    def _parse_prediction_metrics(self, prediction_results: Dict[str, Any]) -> Dict[str, float]:
        """è§£æé¢„æµ‹ç»“æœä¸­çš„æŒ‡æ ‡"""
        metrics = {}
        
        # å°è¯•ä»ä¸åŒå¯èƒ½çš„ä½ç½®æå–æŒ‡æ ‡
        if 'confidence_metrics' in prediction_results:
            conf_metrics = prediction_results['confidence_metrics']
            if isinstance(conf_metrics, dict):
                metrics.update(conf_metrics)
        
        # ç›´æ¥ä»ç»“æœä¸­æå–æ‰€æœ‰æ•°å€¼å­—æ®µ
        numeric_keys = [
            'iptm', 'ptm', 'plddt', 'confidence', 
            'ligand_iptm', 'protein_iptm', 'complex_iplddt',
            'affinity_pred_value', 'ic50_uM', 'pIC50', 'delta_g_kcal_mol', 
            'binding_probability', 'affinity'
        ]
        
        for key in numeric_keys:
            if key in prediction_results:
                try:
                    metrics[key] = float(prediction_results[key])
                except (ValueError, TypeError):
                    logger.warning(f"æ— æ³•è½¬æ¢å­—æ®µ {key} ä¸ºæ•°å€¼: {prediction_results[key]}")
        
        # å¦‚æœæœ‰rankingç»“æœï¼Œä½¿ç”¨rankingä¸­çš„æŒ‡æ ‡
        if 'ranking' in prediction_results:
            ranking = prediction_results['ranking']
            if isinstance(ranking, list) and ranking:
                best_model = ranking[0]
                if isinstance(best_model, dict):
                    for key in ['iptm', 'ptm', 'plddt']:
                        if key in best_model:
                            try:
                                metrics[key] = float(best_model[key])
                            except (ValueError, TypeError):
                                pass
        
        return metrics

class SimpleBatchManager:
    """ç®€åŒ–çš„æ‰¹é‡ä½œä¸šç®¡ç†å™¨"""
    
    def __init__(self, client: BoltzApiClient, config: ScreeningConfig, affinity_enhancer=None):
        self.client = client
        self.config = config
        
        # åœ¨è¾“å‡ºç›®å½•åˆ›å»ºä¸´æ—¶æ–‡ä»¶å¤¹ï¼Œè€Œä¸æ˜¯åœ¨/tmp
        self.temp_dir = os.path.join(config.output_dir, "temp_configs")
        os.makedirs(self.temp_dir, exist_ok=True)
        
        # åˆ›å»ºä»»åŠ¡ç›®å½•
        self.task_dir = os.path.join(config.output_dir, "tasks")
        os.makedirs(self.task_dir, exist_ok=True)
        
        self.active_jobs: Dict[str, Dict] = {}
        
        # äº²å’ŒåŠ›å¢å¼ºå™¨å¼•ç”¨
        self.affinity_enhancer = affinity_enhancer
        
        logger.info(f"ä¸´æ—¶é…ç½®ç›®å½•: {self.temp_dir}")
        logger.info(f"ä»»åŠ¡ç›®å½•: {self.task_dir}")
    
    def prepare_molecule_configs(self, molecules: List[Molecule], target_config: Dict) -> List[str]:
        """ä¸ºåˆ†å­åˆ—è¡¨å‡†å¤‡é…ç½®æ–‡ä»¶"""
        config_files = []
        
        for i, molecule in enumerate(molecules):
            mol_id = f"mol_{i+1:04d}_{molecule.id}"
            config_file = self._create_molecule_config(molecule, target_config, mol_id)
            if config_file:
                config_files.append(config_file)
        
        logger.info(f"å‡†å¤‡äº† {len(config_files)} ä¸ªåˆ†å­é…ç½®æ–‡ä»¶")
        return config_files
    
    def _create_molecule_config(self, molecule: Molecule, target_config: Dict, mol_id: str) -> str:
        """ä¸ºå•ä¸ªåˆ†å­åˆ›å»ºé…ç½®æ–‡ä»¶"""
        try:
            # æ·±æ‹·è´ç›®æ ‡é…ç½®
            import copy
            mol_config = copy.deepcopy(target_config)
            
            # é‡æ–°æ„å»ºsequencesåˆ—è¡¨ï¼Œåªä¿ç•™è›‹ç™½è´¨åºåˆ—
            mol_config['sequences'] = []
            
            # ä»åŸå§‹é…ç½®ä¸­æå–è›‹ç™½è´¨åºåˆ—ï¼Œå¹¶æ”¶é›†å·²ä½¿ç”¨çš„ID
            original_sequences = target_config.get('sequences', [])
            used_ids = set()
            
            for seq in original_sequences:
                if 'protein' in seq:
                    mol_config['sequences'].append(seq)
                    used_ids.add(seq['protein']['id'])
                elif 'ligand' in seq:
                    # è·³è¿‡åŸå§‹é…ä½“ï¼Œæˆ‘ä»¬å°†æ›¿æ¢ä¸ºæ–°çš„å€™é€‰åˆ†å­
                    used_ids.add(seq['ligand']['id'])
            
            # ä¸ºå€™é€‰åˆ†å­è‡ªåŠ¨åˆ†é…ID
            candidate_id = self._assign_molecule_id(used_ids, molecule.mol_type)
            
            # æ·»åŠ å€™é€‰åˆ†å­åºåˆ—
            if molecule.mol_type == "peptide":
                # å¤šè‚½ç±»å‹
                sequence_entry = {
                    "protein": {
                        "id": candidate_id,
                        "sequence": molecule.sequence,
                        "msa": "empty"
                    }
                }
            elif molecule.mol_type == "small_molecule":
                # å°åˆ†å­ç±»å‹ - ä½¿ç”¨ligandæ ¼å¼
                sequence_entry = {
                    "ligand": {
                        "id": candidate_id,
                        "smiles": molecule.sequence  # ç¡®ä¿SMILESæ ¼å¼æ­£ç¡®
                    }
                }
            else:
                logger.warning(f"ä¸æ”¯æŒçš„åˆ†å­ç±»å‹: {molecule.mol_type}")
                return None
            
            # å°†å€™é€‰åˆ†å­æ·»åŠ åˆ°é…ç½®ä¸­
            mol_config["sequences"].append(sequence_entry)
            
            # å¦‚æœæ˜¯å°åˆ†å­ä¸”å¯ç”¨äº†äº²å’ŒåŠ›è®¡ç®—ï¼Œæ·»åŠ propertieséƒ¨åˆ†
            if molecule.mol_type == "small_molecule" and self.affinity_enhancer:
                mol_config["properties"] = [
                    {
                        "affinity": {
                            "binder": candidate_id  # ä½¿ç”¨åŠ¨æ€åˆ†é…çš„é…ä½“ID
                        }
                    }
                ]
                logger.info(f"ä¸ºå°åˆ†å­ {mol_id} æ·»åŠ äº²å’ŒåŠ›è®¡ç®—é…ç½®ï¼Œbinder ID: {candidate_id}")
            
            # ç¡®ä¿versionå­—æ®µå­˜åœ¨
            if 'version' not in mol_config:
                mol_config['version'] = 1
            
            # ä¿å­˜é…ç½®æ–‡ä»¶
            config_path = os.path.join(self.temp_dir, f"{mol_id}.yaml")
            with open(config_path, 'w') as f:
                yaml.dump(mol_config, f, default_flow_style=False, allow_unicode=True)
            
            # éªŒè¯ç”Ÿæˆçš„é…ç½®æ–‡ä»¶
            if not self._validate_config_file(config_path):
                logger.error(f"ç”Ÿæˆçš„é…ç½®æ–‡ä»¶éªŒè¯å¤±è´¥: {config_path}")
                return None
            
            logger.debug(f"åˆ›å»ºåˆ†å­é…ç½®æ–‡ä»¶: {config_path}")
            return config_path
            
        except Exception as e:
            logger.error(f"åˆ›å»ºåˆ†å­é…ç½®å¤±è´¥: {e}")
            return None
    
    def _validate_config_file(self, config_path: str) -> bool:
        """éªŒè¯é…ç½®æ–‡ä»¶æ ¼å¼"""
        try:
            with open(config_path, 'r') as f:
                config = yaml.safe_load(f)
            
            # æ£€æŸ¥å¿…éœ€å­—æ®µ
            if 'sequences' not in config:
                logger.error("é…ç½®æ–‡ä»¶ç¼ºå°‘sequenceså­—æ®µ")
                return False
            
            if not isinstance(config['sequences'], list):
                logger.error("sequenceså­—æ®µå¿…é¡»æ˜¯åˆ—è¡¨")
                return False
            
            if len(config['sequences']) == 0:
                logger.error("sequencesåˆ—è¡¨ä¸èƒ½ä¸ºç©º")
                return False
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„åºåˆ—
            has_protein = False
            has_ligand = False
            
            for seq in config['sequences']:
                if 'protein' in seq:
                    has_protein = True
                    protein = seq['protein']
                    if 'id' not in protein or 'sequence' not in protein:
                        logger.error("è›‹ç™½è´¨åºåˆ—ç¼ºå°‘å¿…éœ€å­—æ®µ")
                        return False
                elif 'ligand' in seq:
                    has_ligand = True
                    ligand = seq['ligand']
                    if 'id' not in ligand or 'smiles' not in ligand:
                        logger.error("é…ä½“åºåˆ—ç¼ºå°‘å¿…éœ€å­—æ®µ")
                        return False
            
            if not has_protein:
                logger.error("é…ç½®æ–‡ä»¶å¿…é¡»åŒ…å«è‡³å°‘ä¸€ä¸ªè›‹ç™½è´¨åºåˆ—")
                return False
            
            logger.debug(f"é…ç½®æ–‡ä»¶éªŒè¯é€šè¿‡: {config_path}")
            return True
            
        except Exception as e:
            logger.error(f"éªŒè¯é…ç½®æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return False
    
    def _assign_molecule_id(self, used_ids: set, mol_type: str) -> str:
        """ä¸ºåˆ†å­è‡ªåŠ¨åˆ†é…å”¯ä¸€ID"""
        # å¸¸ç”¨çš„IDå­—æ¯åºåˆ—
        candidate_letters = ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']
        
        # å°è¯•ä»Bå¼€å§‹åˆ†é…ï¼ˆBé€šå¸¸æ˜¯é…ä½“çš„é»˜è®¤IDï¼‰
        for letter in candidate_letters:
            if letter not in used_ids:
                return letter
        
        # å¦‚æœå­—æ¯ç”¨å®Œäº†ï¼Œä½¿ç”¨æ•°å­—åç¼€
        for i in range(1, 100):
            candidate_id = f"B{i}"
            if candidate_id not in used_ids:
                return candidate_id
        
        # æœ€åçš„å¤‡é€‰æ–¹æ¡ˆ
        return f"MOL_{mol_type}_{len(used_ids)}"
    
    def submit_and_monitor_molecules(self, config_files: List[str], molecules: List[Molecule]) -> Dict[str, Dict]:
        """æäº¤å¹¶ç›‘æ§åˆ†å­"""
        all_results = {}
        
        if self.config.max_workers > 1 and len(config_files) > 1:
            logger.info(f"å¹¶è¡Œå¤„ç† {len(config_files)} ä¸ªåˆ†å­")
            all_results = self._process_parallel(config_files, molecules)
        else:
            logger.info(f"ä¸²è¡Œå¤„ç† {len(config_files)} ä¸ªåˆ†å­")
            all_results = self._process_sequential(config_files, molecules)
        
        return all_results
    
    def _process_sequential(self, config_files: List[str], molecules: List[Molecule]) -> Dict[str, Dict]:
        """ä¸²è¡Œå¤„ç†åˆ†å­"""
        all_results = {}
        
        for i, (config_file, molecule) in enumerate(zip(config_files, molecules)):
            mol_name = f"mol_{i+1:04d}_{molecule.id}"
            
            logger.info(f"æ­£åœ¨å¤„ç†åˆ†å­ {i+1}/{len(config_files)}: {mol_name}")
            
            # æäº¤å•ä¸ªåˆ†å­
            task_id = self.client.submit_screening_job(
                yaml_path=config_file,
                job_name=mol_name,
                use_msa_server=self.config.use_msa_server
            )
            
            if not task_id:
                logger.error(f"åˆ†å­ {mol_name} æäº¤å¤±è´¥")
                continue
            
            logger.info(f"åˆ†å­ {mol_name} æäº¤æˆåŠŸ: {task_id}")
            
            # ç›‘æ§è¿™ä¸ªåˆ†å­ç›´åˆ°å®Œæˆ
            result = self.client.poll_status(task_id, poll_interval=15, max_wait_time=self.config.timeout)
            
            if result:
                all_results[task_id] = result
                status = result.get('status', 'unknown')
                logger.info(f"åˆ†å­ {mol_name} å®Œæˆï¼ŒçŠ¶æ€: {status}")
                
                # ç«‹å³å¤„ç†å®Œæˆçš„ä»»åŠ¡
                if status == 'completed':
                    logger.info(f"ä»»åŠ¡ {task_id} å·²å®Œæˆï¼Œå¼€å§‹ç«‹å³å¤„ç†...")
                    self._process_completed_task_immediately(task_id, molecule, result)
                
                # ä¿å­˜ä»»åŠ¡è®°å½•
                self._save_task_record(task_id, mol_name, molecule, status)
            else:
                logger.error(f"åˆ†å­ {mol_name} ç›‘æ§å¤±è´¥")
        
        return all_results
    
    def _process_parallel(self, config_files: List[str], molecules: List[Molecule]) -> Dict[str, Dict]:
        """å¹¶è¡Œå¤„ç†åˆ†å­"""
        with concurrent.futures.ThreadPoolExecutor(max_workers=self.config.max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_info = {}
            for i, (config_file, molecule) in enumerate(zip(config_files, molecules)):
                mol_name = f"mol_{i+1:04d}_{molecule.id}"
                future = executor.submit(self._process_single_molecule, config_file, mol_name, molecule)
                future_to_info[future] = (mol_name, molecule)
            
            # æ”¶é›†ç»“æœ
            all_results = {}
            for future in concurrent.futures.as_completed(future_to_info):
                mol_name, molecule = future_to_info[future]
                try:
                    task_id, result = future.result()
                    if result:
                        all_results[task_id] = result
                        status = result.get('status', 'unknown')
                        logger.info(f"åˆ†å­ {mol_name} å®Œæˆï¼ŒçŠ¶æ€: {status}")
                        
                        # ä¿å­˜ä»»åŠ¡è®°å½•
                        self._save_task_record(task_id, mol_name, molecule, status)
                except Exception as e:
                    logger.error(f"åˆ†å­ {mol_name} å¤„ç†å¤±è´¥: {e}")
        
        return all_results
    
    def _process_single_molecule(self, config_file: str, mol_name: str, molecule: Molecule) -> Tuple[str, Dict]:
        """å¤„ç†å•ä¸ªåˆ†å­"""
        logger.info(f"å¼€å§‹å¤„ç†åˆ†å­: {mol_name}")
        logger.debug(f"é…ç½®æ–‡ä»¶è·¯å¾„: {config_file}")
        
        # éªŒè¯é…ç½®æ–‡ä»¶å­˜åœ¨
        if not os.path.exists(config_file):
            logger.error(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")
            return None, None
        
        # è¯»å–å¹¶éªŒè¯é…ç½®æ–‡ä»¶å†…å®¹
        try:
            with open(config_file, 'r') as f:
                config_content = f.read()
            logger.debug(f"é…ç½®æ–‡ä»¶å†…å®¹é¢„è§ˆ ({mol_name}):\n{config_content[:500]}...")
        except Exception as e:
            logger.error(f"è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
            return None, None
        
        # æäº¤ä»»åŠ¡
        task_id = self.client.submit_screening_job(
            yaml_path=config_file,
            job_name=mol_name,
            use_msa_server=self.config.use_msa_server
        )
        
        if not task_id:
            logger.error(f"åˆ†å­ {mol_name} æäº¤å¤±è´¥")
            return None, None
        
        logger.info(f"åˆ†å­ {mol_name} æäº¤æˆåŠŸ: {task_id}")
        logger.info(f"å¼€å§‹ç›‘æ§åˆ†å­ {mol_name}...")
        
        # ç›‘æ§ä»»åŠ¡ç›´åˆ°å®Œæˆ
        result = self.client.poll_status(task_id, poll_interval=15, max_wait_time=self.config.timeout)
        
        if result:
            status = result.get('status', 'unknown')
            logger.info(f"åˆ†å­ {mol_name} ç›‘æ§å®Œæˆï¼Œæœ€ç»ˆçŠ¶æ€: {status}")
            logger.info(f"çŠ¶æ€æ£€æŸ¥: status == 'completed' ç»“æœä¸º {status == 'completed'}")
            
            # ç«‹å³å¤„ç†å®Œæˆçš„ä»»åŠ¡
            if status == 'completed':
                logger.info(f"ä»»åŠ¡ {task_id} å·²å®Œæˆï¼Œå¼€å§‹ç«‹å³å¤„ç†...")
                # ç«‹å³ä¸‹è½½å’Œå¤„ç†ç»“æœ
                self._process_completed_task_immediately(task_id, molecule, result)
            elif status == 'failed':
                # å¤„ç†å¤±è´¥ä»»åŠ¡
                error_info = result.get('result', {})
                if isinstance(error_info, dict) and 'error' in error_info:
                    logger.error(f"åˆ†å­ {mol_name} å¤±è´¥åŸå› : {error_info['error']}")
                elif 'traceback' in result:
                    logger.error(f"åˆ†å­ {mol_name} é”™è¯¯å †æ ˆ: {result['traceback']}")
                else:
                    logger.error(f"åˆ†å­ {mol_name} å¤±è´¥ï¼Œä½†æœªè·å–åˆ°è¯¦ç»†é”™è¯¯ä¿¡æ¯")
        else:
            logger.error(f"åˆ†å­ {mol_name} ç›‘æ§å¤±è´¥æˆ–è¶…æ—¶")
        
        return task_id, result
    
    def _save_task_record(self, task_id: str, mol_name: str, molecule: Molecule, status: str):
        """ä¿å­˜ä»»åŠ¡è®°å½•ï¼ŒåŒ…å«å®Œæ•´çš„åˆ†å­ä¿¡æ¯"""
        try:
            record = {
                'task_id': task_id,
                'molecule_name': mol_name,
                'molecule_id': molecule.id,
                'sequence': molecule.sequence.strip() if molecule.sequence else "",  # ç¡®ä¿SMILESè§„èŒƒåŒ–
                'mol_type': molecule.mol_type,
                'status': status,
                'timestamp': time.time(),
                'human_time': time.strftime('%Y-%m-%d %H:%M:%S'),
                'properties': molecule.properties if hasattr(molecule, 'properties') else {}
            }
            
            record_file = os.path.join(self.task_dir, f"task_{task_id}.json")
            with open(record_file, 'w') as f:
                json.dump(record, f, indent=2, ensure_ascii=False)
            
            logger.debug(f"ä»»åŠ¡è®°å½•å·²ä¿å­˜: {record_file}")
                
        except Exception as e:
            logger.warning(f"ä¿å­˜ä»»åŠ¡è®°å½•å¤±è´¥: {e}")
    
    def _process_completed_task_immediately(self, task_id: str, molecule: Molecule, result: Dict):
        """ç«‹å³å¤„ç†å®Œæˆçš„ä»»åŠ¡ï¼ˆä¸‹è½½ç»“æœå¹¶æ·»åŠ åˆ°ç­›é€‰ç»“æœä¸­ï¼‰"""
        try:
            logger.info(f"å¼€å§‹ç«‹å³å¤„ç†ä»»åŠ¡ {task_id}")
            mol_name = f"mol_{molecule.id}_{molecule.name}" if hasattr(molecule, 'name') else f"mol_{molecule.id}"
            
            # ä¸‹è½½ç»“æœåˆ°tasksæ–‡ä»¶å¤¹ä¸‹çš„å•ç‹¬ä»»åŠ¡ç›®å½•
            result_dir = os.path.join(self.config.output_dir, "tasks", f"task_{task_id}")
            logger.info(f"å¼€å§‹ä¸‹è½½ä»»åŠ¡ {task_id} ç»“æœåˆ°: {result_dir}")
            success = self.client.download_results(task_id, result_dir)
            if not success:
                logger.error(f"ä»»åŠ¡ {task_id} ç»“æœä¸‹è½½å¤±è´¥")
                self._save_task_record(task_id, mol_name, molecule, 'failed')
                return False
            
            logger.info(f"ä»»åŠ¡ {task_id} ç»“æœä¸‹è½½å®Œæˆ: {result_dir}")
            
            # è§£æç»“æœ
            logger.info(f"å¼€å§‹è§£æä»»åŠ¡ {task_id} ç»“æœ")
            prediction_results = self._parse_result_dir(result_dir)
            if not prediction_results:
                logger.error(f"ä»»åŠ¡ {task_id} ç»“æœè§£æå¤±è´¥")
                self._save_task_record(task_id, mol_name, molecule, 'failed')
                return False
            
            logger.info(f"ä»»åŠ¡ {task_id} ç»“æœè§£ææˆåŠŸ: {prediction_results}")
            
            # è®¡ç®—è¯„åˆ†å¹¶åˆ›å»ºç­›é€‰ç»“æœ
            if hasattr(self, 'engine') and self.engine:
                logger.info(f"å¼€å§‹ä¸ºä»»åŠ¡ {task_id} è®¡ç®—è¯„åˆ†")
                screening_result = self.engine.scoring_system.score_molecule(molecule, prediction_results)
                screening_result.structure_path = result_dir
                
                # ç›´æ¥æ·»åŠ åˆ°å¼•æ“çš„ç»“æœåˆ—è¡¨ä¸­
                self.engine.screening_results.append(screening_result)
                logger.info(f"ä»»åŠ¡ {task_id} å¤„ç†æˆåŠŸï¼Œè¯„åˆ†: {screening_result.combined_score:.4f}")
            else:
                logger.warning(f"æ— æ³•è®¿é—®engineæˆ–scoring_systemï¼Œä»»åŠ¡ {task_id} ç»“æœæœªè¯„åˆ†")
                logger.warning(f"hasattr(self, 'engine'): {hasattr(self, 'engine')}")
                if hasattr(self, 'engine'):
                    logger.warning(f"self.engine: {self.engine}")
            
            # ä¿å­˜æˆåŠŸçš„ä»»åŠ¡è®°å½•
            self._save_task_record(task_id, mol_name, molecule, 'completed')
            return True
            
        except Exception as e:
            logger.error(f"ç«‹å³å¤„ç†ä»»åŠ¡ {task_id} å¤±è´¥: {e}")
            import traceback
            logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            self._save_task_record(task_id, mol_name, molecule, 'failed')
            return False
    
    def _parse_result_dir(self, result_dir: str) -> Dict[str, Any]:
        """è§£æç»“æœç›®å½•ï¼Œæå–é¢„æµ‹æŒ‡æ ‡"""
        try:
            result_data = {}
            
            # 1. æŸ¥æ‰¾confidence_data_model_0.jsonæ–‡ä»¶ï¼ˆå®é™…çš„æ–‡ä»¶åï¼‰
            confidence_file = os.path.join(result_dir, "confidence_data_model_0.json")
            if os.path.exists(confidence_file):
                with open(confidence_file, 'r') as f:
                    confidence_data = json.load(f)
                
                # æå–confidenceç›¸å…³æŒ‡æ ‡ï¼Œä½¿ç”¨å®é™…çš„å­—æ®µå
                result_data.update({
                    'confidence': confidence_data.get('confidence_score', 0.0),
                    'iptm': confidence_data.get('iptm', 0.0),
                    'ptm': confidence_data.get('ptm', 0.0),
                    'plddt': confidence_data.get('complex_plddt', 0.0),
                    'ligand_iptm': confidence_data.get('ligand_iptm', 0.0),
                    'protein_iptm': confidence_data.get('protein_iptm', 0.0),
                    'complex_iplddt': confidence_data.get('complex_iplddt', 0.0)
                })
                logger.debug(f"è¯»å–ç½®ä¿¡åº¦æ•°æ®: confidence={result_data['confidence']:.4f}, iptm={result_data['iptm']:.4f}, ptm={result_data['ptm']:.4f}")
            
            # 2. æŸ¥æ‰¾affinity_data.jsonæ–‡ä»¶ï¼ˆäº²å’ŒåŠ›æ•°æ®ï¼‰
            affinity_file = os.path.join(result_dir, "affinity_data.json")
            if os.path.exists(affinity_file):
                with open(affinity_file, 'r') as f:
                    affinity_data = json.load(f)
                
                # æå–äº²å’ŒåŠ›é¢„æµ‹å€¼
                affinity_pred = affinity_data.get('affinity_pred_value', None)
                binding_prob = affinity_data.get('affinity_probability_binary', None)
                
                if affinity_pred is not None:
                    # è®¡ç®—IC50ç›¸å…³æŒ‡æ ‡
                    # æ ¹æ®æ–‡æ¡£ï¼šaffinity_pred_valueæ˜¯log(IC50)ï¼Œå•ä½ä¸ºÎ¼M
                    # IC50 (Î¼M) = 10^affinity_pred_value
                    ic50_uM = 10 ** affinity_pred
                    
                    # è®¡ç®—pIC50 = -log10(IC50_M) = -log10(IC50_uM * 1e-6) = 6 - log10(IC50_uM)
                    pIC50 = 6 - affinity_pred
                    
                    # è®¡ç®—ç»“åˆè‡ªç”±èƒ½ Î”G (kcal/mol) = (6 - affinity_pred) * 1.364
                    delta_g_kcal_mol = pIC50 * 1.364
                    
                    result_data.update({
                        'affinity_pred_value': affinity_pred,  # åŸå§‹é¢„æµ‹å€¼
                        'ic50_uM': ic50_uM,                    # IC50 (Î¼M)
                        'pIC50': pIC50,                        # pIC50
                        'delta_g_kcal_mol': delta_g_kcal_mol,  # Î”G (kcal/mol)
                        'binding_probability': binding_prob,    # ç»“åˆæ¦‚ç‡
                        'affinity': affinity_pred  # ç”¨äºåç»­è®¡ç®—
                    })
                    
                    logger.debug(f"è¯»å–äº²å’ŒåŠ›æ•°æ®: é¢„æµ‹å€¼={affinity_pred:.4f}, IC50={ic50_uM:.2f}Î¼M, pIC50={pIC50:.2f}, Î”G={delta_g_kcal_mol:.2f}kcal/mol")
            
            # 3. å…¼å®¹æ—§æ ¼å¼ï¼šæŸ¥æ‰¾confidence_metrics.json
            if not result_data:
                confidence_metrics_file = os.path.join(result_dir, "confidence_metrics.json")
                if os.path.exists(confidence_metrics_file):
                    with open(confidence_metrics_file, 'r') as f:
                        return json.load(f)
            
            return result_data if result_data else {}
            
        except Exception as e:
            logger.error(f"è§£æç»“æœç›®å½•å¤±è´¥: {e}")
            import traceback
            logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            return None

    def cleanup(self):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        try:
            # åªæœ‰åœ¨æˆåŠŸæ—¶æ‰æ¸…ç†ï¼Œå¤±è´¥æ—¶ä¿ç•™ä»¥ä¾¿è°ƒè¯•
            if hasattr(self, '_cleanup_enabled') and self._cleanup_enabled:
                if os.path.exists(self.temp_dir):
                    shutil.rmtree(self.temp_dir)
                    logger.info(f"æ¸…ç†ä¸´æ—¶ç›®å½•: {self.temp_dir}")
            else:
                logger.info(f"ä¿ç•™ä¸´æ—¶ç›®å½•ä»¥ä¾¿è°ƒè¯•: {self.temp_dir}")
        except Exception as e:
            logger.warning(f"æ¸…ç†ä¸´æ—¶ç›®å½•å¤±è´¥: {e}")

class SimpleScreeningEngine:
    """ç®€åŒ–ç‰ˆè™šæ‹Ÿç­›é€‰å¼•æ“"""
    
    def __init__(self, client: BoltzApiClient, config: ScreeningConfig):
        self.client = client
        self.config = config
        self.scoring_system = ScoringSystem(config.scoring_weights)
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(config.output_dir, exist_ok=True)
        
        # åˆå§‹åŒ–ç»“æœå­˜å‚¨
        self.screening_results: List[ScreeningResult] = []
        self.failed_molecules: List[str] = []
        
        # åˆå§‹åŒ–äº²å’ŒåŠ›è®¡ç®—å™¨ï¼ˆæ™ºèƒ½åˆ¤æ–­æ˜¯å¦éœ€è¦ï¼‰
        self.affinity_enhancer = None
        self._auto_enable_affinity_calculation()
        
        # åˆ›å»ºç®€åŒ–çš„æ‰¹å¤„ç†ç®¡ç†å™¨
        self.batch_manager = SimpleBatchManager(client, config, self.affinity_enhancer)
        # å»ºç«‹åŒå‘å¼•ç”¨ï¼Œè®©batch_managerèƒ½å¤Ÿè®¿é—®engineçš„scoring_system
        self.batch_manager.engine = self
        
        logger.info(f"ç®€åŒ–ç‰ˆè™šæ‹Ÿç­›é€‰å¼•æ“å·²åˆå§‹åŒ–ï¼Œè¾“å‡ºç›®å½•: {config.output_dir}")
        if self.affinity_enhancer:
            logger.info("äº²å’ŒåŠ›è®¡ç®—å·²å¯ç”¨")
    
    def _auto_enable_affinity_calculation(self):
        """è‡ªåŠ¨åˆ¤æ–­æ˜¯å¦å¯ç”¨äº²å’ŒåŠ›è®¡ç®—"""
        try:
            logger.info("å¼€å§‹è‡ªåŠ¨å¯ç”¨äº²å’ŒåŠ›è®¡ç®—æ£€æŸ¥")
            
            # å¦‚æœç”¨æˆ·æ˜ç¡®ç¦ç”¨äº†è‡ªåŠ¨å¯ç”¨åŠŸèƒ½
            if hasattr(self.config, 'auto_enable_affinity') and not self.config.auto_enable_affinity:
                logger.info("ç”¨æˆ·å·²ç¦ç”¨è‡ªåŠ¨å¯ç”¨äº²å’ŒåŠ›è®¡ç®—åŠŸèƒ½")
                return
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯å°åˆ†å­ç­›é€‰
            if hasattr(self.config, 'library_type') and self.config.library_type in ['small_molecule', 'ligand', 'compound', 'chemical']:
                logger.info(f"æ£€æµ‹åˆ°å°åˆ†å­ç­›é€‰ï¼Œlibrary_type: {self.config.library_type}")
                
                # å°è¯•ä»ç›®æ ‡YAMLæ–‡ä»¶è·å–è›‹ç™½è´¨åºåˆ—
                target_sequence = self._extract_target_protein_sequence()
                
                if target_sequence:
                    logger.info(f"ä»ç›®æ ‡æ–‡ä»¶æå–åˆ°è›‹ç™½è´¨åºåˆ—: {len(target_sequence)} ä¸ªæ°¨åŸºé…¸")
                    try:
                        self.affinity_enhancer = SmallMoleculeAffinityEnhancer(self.client, target_sequence)
                        # è‡ªåŠ¨æ›´æ–°é…ç½®æ ‡è®°
                        self.config.enable_affinity = True
                        logger.info(f"æˆåŠŸæå–è›‹ç™½è´¨åºåˆ—ï¼Œé•¿åº¦: {len(target_sequence)}")
                        logger.info("ğŸ§ª äº²å’ŒåŠ›è®¡ç®—å·²è‡ªåŠ¨å¯ç”¨ï¼ˆåŸºäºlibrary_typeæ£€æµ‹ï¼‰")
                        return
                    except Exception as e:
                        logger.error(f"åˆ›å»ºSmallMoleculeAffinityEnhancerå¤±è´¥: {e}")
                        self.affinity_enhancer = None
                else:
                    logger.warning("æ— æ³•è·å–ç›®æ ‡è›‹ç™½è´¨åºåˆ—ï¼Œäº²å’ŒåŠ›è®¡ç®—æœªå¯ç”¨")
                    self.affinity_enhancer = None
            else:
                logger.info(f"åŸºäºlibrary_typeæ£€æµ‹ï¼šéå°åˆ†å­ç­›é€‰ (library_type: {getattr(self.config, 'library_type', 'None')})")
            
        except Exception as e:
            logger.error(f"è‡ªåŠ¨å¯ç”¨äº²å’ŒåŠ›è®¡ç®—æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            self.affinity_enhancer = None
    
    def _extract_target_protein_sequence(self) -> Optional[str]:
        """ä»ç›®æ ‡YAMLæ–‡ä»¶ä¸­æå–è›‹ç™½è´¨åºåˆ—"""
        try:
            with open(self.config.target_yaml, 'r') as f:
                target_config = yaml.safe_load(f)
            
            sequences = target_config.get('sequences', [])
            for seq in sequences:
                if 'protein' in seq:
                    protein_seq = seq['protein'].get('sequence', '')
                    if protein_seq:
                        return protein_seq
            
            logger.warning("åœ¨ç›®æ ‡é…ç½®æ–‡ä»¶ä¸­æœªæ‰¾åˆ°è›‹ç™½è´¨åºåˆ—")
            return None
            
        except Exception as e:
            logger.error(f"æå–ç›®æ ‡è›‹ç™½è´¨åºåˆ—å¤±è´¥: {e}")
            return None
    
    def run_screening(self) -> bool:
        """è¿è¡Œç®€åŒ–çš„è™šæ‹Ÿç­›é€‰æµç¨‹"""
        try:
            logger.info("å¼€å§‹è™šæ‹Ÿç­›é€‰æµç¨‹")
            start_time = time.time()
            
            # æ£€æŸ¥æ˜¯å¦æ”¯æŒç»­ç®—
            if self._should_resume():
                logger.info("æ£€æµ‹åˆ°ç°æœ‰ç»“æœï¼Œå¯ç”¨ç»­ç®—æ¨¡å¼")
                return self._resume_screening()
            
            # å¼€å§‹æ–°çš„ç­›é€‰
            logger.info("å¼€å§‹æ–°çš„ç­›é€‰ä»»åŠ¡")
            return self._run_new_screening()
            
        except Exception as e:
            logger.error(f"è™šæ‹Ÿç­›é€‰è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            return False
        finally:
            # æ¸…ç†èµ„æº
            self.batch_manager.cleanup()
    
    def _should_resume(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥ç»­ç®—"""
        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ç»“æœæ–‡ä»¶æˆ–ä»»åŠ¡è®°å½•
        results_file = os.path.join(self.config.output_dir, "screening_results_complete.csv")
        task_dir = os.path.join(self.config.output_dir, "tasks")
        
        # å¦‚æœæœ‰ç»“æœæ–‡ä»¶æˆ–ä»»åŠ¡ç›®å½•å­˜åœ¨ï¼Œåˆ™æ”¯æŒç»­ç®—
        return os.path.exists(results_file) or (os.path.exists(task_dir) and os.listdir(task_dir))
    
    def _get_completed_smiles(self) -> set:
        """è·å–å·²å®Œæˆè®¡ç®—çš„SMILESé›†åˆï¼Œæ”¯æŒä»å¤šä¸ªæºåŠ è½½"""
        completed_smiles = set()
        
        # 1. ä»ç»“æœæ–‡ä»¶ä¸­åŠ è½½å·²å®Œæˆçš„SMILES
        results_file = os.path.join(self.config.output_dir, "screening_results_complete.csv")
        if os.path.exists(results_file):
            try:
                df = pd.read_csv(results_file)
                if 'sequence' in df.columns:
                    for sequence in df['sequence'].dropna():
                        if sequence.strip():  # ç¡®ä¿ä¸æ˜¯ç©ºå­—ç¬¦ä¸²
                            completed_smiles.add(sequence.strip())
                    logger.info(f"ä»ç»“æœæ–‡ä»¶åŠ è½½äº† {len(completed_smiles)} ä¸ªå·²å®Œæˆçš„SMILES")
            except Exception as e:
                logger.warning(f"è¯»å–ç»“æœæ–‡ä»¶å¤±è´¥: {e}")
        
        # 2. ä»ä»»åŠ¡è®°å½•ä¸­åŠ è½½å·²å®Œæˆçš„SMILES
        task_dir = os.path.join(self.config.output_dir, "tasks")
        if os.path.exists(task_dir):
            task_smiles = 0
            for task_file in os.listdir(task_dir):
                if task_file.endswith('.json'):
                    try:
                        task_path = os.path.join(task_dir, task_file)
                        with open(task_path, 'r') as f:
                            task_record = json.load(f)
                        
                        # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦æˆåŠŸå®Œæˆ
                        if task_record.get('status') == 'completed':
                            sequence = task_record.get('sequence', '').strip()
                            if sequence:
                                completed_smiles.add(sequence)
                                task_smiles += 1
                                
                    except Exception as e:
                        logger.warning(f"è¯»å–ä»»åŠ¡è®°å½• {task_file} å¤±è´¥: {e}")
            
            if task_smiles > 0:
                logger.info(f"ä»ä»»åŠ¡è®°å½•åŠ è½½äº†é¢å¤– {task_smiles} ä¸ªå·²å®Œæˆçš„SMILES")
        
        logger.info(f"æ€»è®¡åŠ è½½äº† {len(completed_smiles)} ä¸ªå·²å®Œæˆçš„SMILESç”¨äºç»­ç®—")
        return completed_smiles
    
    def _resume_screening(self) -> bool:
        """æ™ºèƒ½ç»­ç®—ç­›é€‰"""
        try:
            # 1. åŠ è½½åˆ†å­åº“
            library = self._load_molecule_library()
            if not library:
                return False
            
            # 2. è·å–å·²å®Œæˆçš„SMILESé›†åˆï¼ˆæ™ºèƒ½åŠ è½½ï¼‰
            completed_smiles = self._get_completed_smiles()
            
            # 3. åŠ è½½å·²æœ‰ç»“æœåˆ°å†…å­˜ä¸­
            existing_results = self._load_existing_results()
            if existing_results:
                self.screening_results = existing_results
                logger.info(f"åŠ è½½äº† {len(existing_results)} ä¸ªå·²æœ‰ç»“æœ")
            
            # 4. é¦–å…ˆåº”ç”¨max_moleculesé™åˆ¶åˆ°åŸå§‹åˆ†å­åˆ—è¡¨
            molecules_to_process = library.molecules
            if self.config.max_molecules > 0:
                molecules_to_process = molecules_to_process[:self.config.max_molecules]
                logger.info(f"åº”ç”¨max_moleculesé™åˆ¶: {len(library.molecules)} -> {len(molecules_to_process)}")
            
            # 5. ç­›é€‰æœªå®Œæˆçš„åˆ†å­ï¼ˆåŸºäºSMILESæ¯”è¾ƒï¼‰
            remaining_molecules = []
            skipped_count = 0
            
            for mol in molecules_to_process:
                mol_smiles = mol.sequence.strip() if mol.sequence else ""
                if mol_smiles and mol_smiles in completed_smiles:
                    skipped_count += 1
                    continue
                remaining_molecules.append(mol)
            
            logger.info(f"ç»­ç®—åˆ†æ: é™åˆ¶ååˆ†å­æ•° {len(molecules_to_process)}, å·²å®Œæˆ {skipped_count}, å¾…å¤„ç† {len(remaining_molecules)}")
            
            # 6. å¦‚æœæ²¡æœ‰å¾…å¤„ç†çš„åˆ†å­ï¼Œç›´æ¥å¤„ç†ç°æœ‰ç»“æœ
            if not remaining_molecules:
                logger.info("æ‰€æœ‰åˆ†å­éƒ½å·²å®Œæˆè®¡ç®—")
                if self.screening_results:
                    self._process_and_save_results()
                    return True
                else:
                    logger.warning("æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„ç­›é€‰ç»“æœ")
                    return False
            
            # 6. å¤„ç†å‰©ä½™åˆ†å­
            logger.info(f"ç»§ç»­å¤„ç†å‰©ä½™çš„ {len(remaining_molecules)} ä¸ªåˆ†å­...")
            return self._process_molecules(remaining_molecules)
            
        except Exception as e:
            logger.error(f"æ™ºèƒ½ç»­ç®—å¤±è´¥: {e}")
            import traceback
            logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            return False
    
    def _run_new_screening(self) -> bool:
        """è¿è¡Œæ–°çš„ç­›é€‰"""
        try:
            # 1. åŠ è½½åˆ†å­åº“
            library = self._load_molecule_library()
            if not library:
                return False
            
            # 2. é¢„å¤„ç†åˆ†å­
            molecules = self._preprocess_molecules(library)
            if not molecules:
                return False
            
            # 3. å¤„ç†åˆ†å­
            return self._process_molecules(molecules)
            
        except Exception as e:
            logger.error(f"æ–°ç­›é€‰å¤±è´¥: {e}")
            return False
    
    def _load_molecule_library(self) -> Optional[MoleculeLibrary]:
        """åŠ è½½åˆ†å­åº“"""
        try:
            library = LibraryProcessor.create_library(self.config.library_path, self.config.library_type)
            success = library.load_library()
            if not success:
                logger.error("åˆ†å­åº“åŠ è½½å¤±è´¥")
                return None
            logger.info(f"æˆåŠŸåŠ è½½{library.mol_type}åº“: {len(library.molecules)} ä¸ªåˆ†å­")
            return library
        except Exception as e:
            logger.error(f"åŠ è½½åˆ†å­åº“å¤±è´¥: {e}")
            return None
    
    def _load_existing_results(self) -> List[ScreeningResult]:
        """åŠ è½½å·²æœ‰ç»“æœ"""
        results_file = os.path.join(self.config.output_dir, "screening_results_complete.csv")
        if not os.path.exists(results_file):
            return []
        
        try:
            df = pd.read_csv(results_file)
            results = []
            
            for _, row in df.iterrows():
                result = ScreeningResult(
                    molecule_id=row.get('molecule_id', ''),
                    molecule_name=row.get('molecule_name', ''),
                    sequence=row.get('sequence', ''),
                    mol_type=row.get('mol_type', ''),
                    binding_score=float(row.get('binding_score', 0.0)),
                    confidence_score=float(row.get('confidence_score', 0.0)),
                    structural_score=float(row.get('structural_score', 0.0)),
                    combined_score=float(row.get('combined_score', 0.0)),
                    rank=int(row.get('rank', 0)),
                    structure_path=row.get('structure_path', ''),
                    properties={}
                )
                results.append(result)
            
            logger.info(f"åŠ è½½äº† {len(results)} ä¸ªå·²æœ‰ç»“æœ")
            return results
            
        except Exception as e:
            logger.error(f"åŠ è½½å·²æœ‰ç»“æœå¤±è´¥: {e}")
            return []
    
    def _preprocess_molecules(self, library: MoleculeLibrary) -> List[Molecule]:
        """é¢„å¤„ç†åˆ†å­"""
        molecules = library.molecules
        
        # é™åˆ¶åˆ†å­æ•°é‡
        if self.config.max_molecules > 0:
            molecules = molecules[:self.config.max_molecules]
            logger.info(f"é™åˆ¶ç­›é€‰åˆ†å­æ•°é‡ä¸º: {self.config.max_molecules}")
        
        logger.info(f"é¢„å¤„ç†åæœ‰æ•ˆåˆ†å­æ•°é‡: {len(molecules)}")
        
        # æ£€æµ‹åˆ†å­ç±»å‹å¹¶è®°å½•
        if molecules:
            sample_mol = molecules[0]
            logger.info(f"âœ“ å·²æ£€æµ‹åˆ° {len(molecules)} ä¸ª{sample_mol.mol_type}ï¼Œäº²å’ŒåŠ›è®¡ç®—å·²{'å¯ç”¨' if self.affinity_enhancer else 'æœªå¯ç”¨'}")
        
        return molecules
    
    def _process_molecules(self, molecules: List[Molecule]) -> bool:
        """å¤„ç†åˆ†å­åˆ—è¡¨"""
        try:
            # 1. åŠ è½½ç›®æ ‡é…ç½®
            target_config = self._load_target_config()
            if not target_config:
                return False
            
            # 2. å‡†å¤‡åˆ†å­é…ç½®
            config_files = self.batch_manager.prepare_molecule_configs(molecules, target_config)
            if not config_files:
                logger.error("å‡†å¤‡åˆ†å­é…ç½®å¤±è´¥")
                return False
            
            # 3. æäº¤å¹¶ç›‘æ§åˆ†å­
            job_results = self.batch_manager.submit_and_monitor_molecules(config_files, molecules)
            
            # 4. æ”¶é›†ç»“æœ
            success = self._collect_results(job_results, molecules)
            if not success:
                logger.error("æ”¶é›†ç»“æœå¤±è´¥")
                return False
            
            # 5. å¤„ç†å’Œä¿å­˜ç»“æœ
            self._process_and_save_results()
            
            # æ ‡è®°å¯ä»¥æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            self.batch_manager._cleanup_enabled = True
            
            return True
            
        except Exception as e:
            logger.error(f"å¤„ç†åˆ†å­å¤±è´¥: {e}")
            return False
    
    def _load_target_config(self) -> Optional[Dict]:
        """åŠ è½½ç›®æ ‡é…ç½®"""
        try:
            with open(self.config.target_yaml, 'r') as f:
                config = yaml.safe_load(f)
            logger.info(f"æˆåŠŸåŠ è½½ç›®æ ‡é…ç½®: {self.config.target_yaml}")
            return config
        except Exception as e:
            logger.error(f"åŠ è½½ç›®æ ‡é…ç½®å¤±è´¥: {e}")
            return None
    
    def _collect_results(self, job_results: Dict[str, Dict], molecules: List[Molecule]) -> bool:
        """æ”¶é›†å’Œå¤„ç†ç»“æœï¼ˆç°åœ¨åªéœ€è¦ç»Ÿè®¡ï¼Œå› ä¸ºç»“æœå·²ç»å®æ—¶å¤„ç†äº†ï¼‰"""
        try:
            successful_count = 0
            failed_count = 0
            
            for task_id, result in job_results.items():
                status = result.get('status', 'unknown')
                
                if status == 'completed':
                    successful_count += 1
                else:
                    failed_count += 1
                    logger.warning(f"ä»»åŠ¡ {task_id} å¤±è´¥: {status}")
            
            logger.info(f"ç»“æœæ”¶é›†å®Œæˆ: æˆåŠŸ {successful_count}, å¤±è´¥ {failed_count}")
            return successful_count > 0
            
        except Exception as e:
            logger.error(f"æ”¶é›†ç»“æœæ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return False
    
    def _find_molecule_for_task(self, task_id: str, molecules: List[Molecule]) -> Optional[Molecule]:
        """æ ¹æ®ä»»åŠ¡IDæ‰¾åˆ°å¯¹åº”çš„åˆ†å­"""
        # ä»ä»»åŠ¡è®°å½•ä¸­æŸ¥æ‰¾
        record_file = os.path.join(self.batch_manager.task_dir, f"task_{task_id}.json")
        if os.path.exists(record_file):
            try:
                with open(record_file, 'r') as f:
                    record = json.load(f)
                molecule_id = record.get('molecule_id', '')
                
                # åœ¨åˆ†å­åˆ—è¡¨ä¸­æŸ¥æ‰¾
                for molecule in molecules:
                    if molecule.id == molecule_id:
                        return molecule
            except Exception as e:
                logger.warning(f"è¯»å–ä»»åŠ¡è®°å½•å¤±è´¥: {e}")
        
        # å¦‚æœæ‰¾ä¸åˆ°ï¼Œè¿”å›None
        return None
    
    def _process_and_save_results(self):
        """å¤„ç†å’Œä¿å­˜æœ€ç»ˆç»“æœ"""
        try:
            if not self.screening_results:
                logger.warning("æ²¡æœ‰å¯ä¿å­˜çš„ç­›é€‰ç»“æœ")
                return
            
            # ç§»é™¤å¤šä½™çš„äº²å’ŒåŠ›å¢å¼ºæ­¥éª¤ï¼Œå› ä¸ºç¬¬ä¸€æ¬¡ç»“æ„é¢„æµ‹å°±åŒ…å«äº†äº²å’ŒåŠ›æ•°æ®
            logger.info("äº²å’ŒåŠ›æ•°æ®å·²åœ¨ç»“æ„é¢„æµ‹é˜¶æ®µè®¡ç®—å®Œæˆï¼Œè·³è¿‡äºŒæ¬¡è®¡ç®—")
            
            # æŒ‰ç»¼åˆè¯„åˆ†æ’åº
            self.screening_results.sort(key=lambda x: x.combined_score, reverse=True)
            
            # åˆ†é…æ’å
            for i, result in enumerate(self.screening_results):
                result.rank = i + 1
            
            # ä¿å­˜å®Œæ•´ç»“æœ
            self._save_complete_results()
            
            # ä¿å­˜Topç»“æœ
            self._save_top_results()
            
            # ç”Ÿæˆæ‘˜è¦
            self._save_summary()
            
            # ç”ŸæˆHTMLæŠ¥å‘Š
            if self.config.generate_plots:
                self._generate_html_report()
            
            logger.info(f"ç»“æœå¤„ç†å®Œæˆï¼Œå…± {len(self.screening_results)} ä¸ªç»“æœ")
            
        except Exception as e:
            logger.error(f"å¤„ç†å’Œä¿å­˜ç»“æœå¤±è´¥: {e}")
    
    def _save_complete_results(self):
        """ä¿å­˜å®Œæ•´ç»“æœ"""
        try:
            results_data = []
            for result in self.screening_results:
                row = {
                    'rank': result.rank,
                    'molecule_id': result.molecule_id,
                    'molecule_name': result.molecule_name,
                    'sequence': result.sequence,
                    'mol_type': result.mol_type,
                    'combined_score': result.combined_score,
                    'binding_score': result.binding_score,
                    'structural_score': result.structural_score,
                    'confidence_score': result.confidence_score,
                    'structure_path': result.structure_path
                }
                
                # æ·»åŠ å±æ€§ä¿¡æ¯
                if result.properties:
                    row.update(result.properties)
                
                results_data.append(row)
            
            df = pd.DataFrame(results_data)
            results_file = os.path.join(self.config.output_dir, "screening_results_complete.csv")
            df.to_csv(results_file, index=False, encoding='utf-8')
            
            logger.info(f"å®Œæ•´ç»“æœå·²ä¿å­˜: {results_file}")
            
        except Exception as e:
            logger.error(f"ä¿å­˜å®Œæ•´ç»“æœå¤±è´¥: {e}")
    
    def _save_top_results(self):
        """ä¿å­˜Topç»“æœ"""
        try:
            top_results = self.screening_results[:self.config.top_n]
            
            results_data = []
            for result in top_results:
                row = {
                    'rank': result.rank,
                    'molecule_id': result.molecule_id,
                    'molecule_name': result.molecule_name,
                    'sequence': result.sequence,
                    'mol_type': result.mol_type,
                    'combined_score': result.combined_score,
                    'binding_score': result.binding_score,
                    'structural_score': result.structural_score,
                    'confidence_score': result.confidence_score,
                    'structure_path': result.structure_path
                }
                results_data.append(row)
            
            df = pd.DataFrame(results_data)
            top_file = os.path.join(self.config.output_dir, "top_hits.csv")
            df.to_csv(top_file, index=False, encoding='utf-8')
            
            logger.info(f"Top {len(top_results)} ç»“æœå·²ä¿å­˜: {top_file}")
            
        except Exception as e:
            logger.error(f"ä¿å­˜Topç»“æœå¤±è´¥: {e}")
    
    def _save_summary(self):
        """ä¿å­˜ç­›é€‰æ‘˜è¦"""
        try:
            summary = {
                'total_screened': len(self.screening_results),
                'successful_predictions': len(self.screening_results),
                'failed_predictions': len(self.failed_molecules),
                'success_rate': len(self.screening_results) / (len(self.screening_results) + len(self.failed_molecules)) if (len(self.screening_results) + len(self.failed_molecules)) > 0 else 0,
                'top_score': self.screening_results[0].combined_score if self.screening_results else 0.0,
                'average_score': np.mean([r.combined_score for r in self.screening_results]) if self.screening_results else 0.0,
                'screening_config': asdict(self.config),
                'timestamp': time.time()
            }
            
            summary_file = os.path.join(self.config.output_dir, "screening_summary.json")
            with open(summary_file, 'w', encoding='utf-8') as f:
                json.dump(summary, f, indent=2, ensure_ascii=False)
            
            logger.info(f"ç­›é€‰æ‘˜è¦å·²ä¿å­˜: {summary_file}")
            
        except Exception as e:
            logger.error(f"ä¿å­˜ç­›é€‰æ‘˜è¦å¤±è´¥: {e}")
    
    def _generate_html_report(self):
        """ç”ŸæˆHTMLæŠ¥å‘Š"""
        try:
            logger.info("å¼€å§‹ç”ŸæˆHTMLæŠ¥å‘Š...")
            
            # åˆ›å»ºHTMLæŠ¥å‘Šç”Ÿæˆå™¨
            reporter = HTMLReporter(
                screening_results=self.screening_results,
                output_dir=self.config.output_dir
            )
            
            # å…ˆç”Ÿæˆå›¾è¡¨
            plots = reporter.generate_screening_plots()
            logger.info(f"ç”Ÿæˆäº† {len(plots)} ä¸ªå›¾è¡¨")
            
            # å†ç”ŸæˆHTMLæŠ¥å‘Š
            report_path = reporter.generate_html_report(plots=plots)
            
            if report_path and os.path.exists(report_path):
                logger.info(f"HTMLæŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
            else:
                logger.warning("HTMLæŠ¥å‘Šç”Ÿæˆå¤±è´¥ï¼Œä½†å›¾è¡¨å·²ç”Ÿæˆ")
                
        except Exception as e:
            logger.error(f"ç”ŸæˆHTMLæŠ¥å‘Šå¤±è´¥: {e}")
            import traceback
            logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
    
    def get_screening_summary(self) -> Dict[str, Any]:
        """è·å–ç­›é€‰æ‘˜è¦"""
        return {
            'total_screened': len(self.screening_results),
            'successful_predictions': len(self.screening_results),
            'failed_predictions': len(self.failed_molecules),
            'success_rate': len(self.screening_results) / (len(self.screening_results) + len(self.failed_molecules)) if (len(self.screening_results) + len(self.failed_molecules)) > 0 else 0,
            'top_score': self.screening_results[0].combined_score if self.screening_results else 0.0
        }
