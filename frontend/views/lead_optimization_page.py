import io
import json
import os
import time
import zipfile
import string
from typing import List, Tuple

import pandas as pd
import streamlit as st
import yaml
from frontend.lead_optimization_client import (
    submit_lead_optimization,
    get_lead_optimization_status,
    download_lead_optimization_results,
    terminate_task,
)
from frontend.ui_components import render_pocket_constraint_ui
from frontend.url_state import URLStateManager
from frontend.utils import (
    get_smart_msa_default,
    read_cif_from_string,
    extract_protein_residue_bfactors,
    visualize_structure_py3dmol,
    get_pair_iptm_from_confidence,
)
from frontend.constants import BACKEND_LABELS
from config import LEAD_OPTIMIZATION_OUTPUT_DIR


def _get_chain_id_by_index(index: int) -> str:
    if index < 26:
        return string.ascii_uppercase[index]
    return f"Z{index-25}"


def _get_next_chain_id(chain_counter: int) -> Tuple[str, int]:
    chain_id = _get_chain_id_by_index(chain_counter)
    return chain_id, chain_counter + 1


def _get_chain_ids_for_components(components: List[dict]) -> Tuple[List[str], dict]:
    chain_ids = []
    chain_descriptions = {}
    chain_counter = 0

    for comp in components:
        comp_type = comp.get('type', 'protein')
        sequence = comp.get('sequence', '').strip()
        num_copies = max(1, int(comp.get('num_copies', 1)))

        for copy_idx in range(num_copies):
            chain_id, chain_counter = _get_next_chain_id(chain_counter)
            chain_ids.append(chain_id)

            if comp_type == 'protein':
                type_icon = 'ğŸ§¬'
            elif comp_type == 'dna':
                type_icon = 'ğŸ”—'
            elif comp_type == 'rna':
                type_icon = 'ğŸ“œ'
            else:
                type_icon = 'ğŸ”¸'

            seq_status = "" if sequence else " (åºåˆ—å¾…è¾“å…¥)"
            if num_copies > 1:
                chain_descriptions[chain_id] = f"{type_icon} é“¾ {chain_id} ({comp_type.upper()} æ‹·è´ {copy_idx+1}/{num_copies}){seq_status}"
            else:
                chain_descriptions[chain_id] = f"{type_icon} é“¾ {chain_id} ({comp_type.upper()}){seq_status}"

    return chain_ids, chain_descriptions


def _normalize_pocket_constraints(constraints: List[dict], binder_chain_id: str) -> List[dict]:
    normalized = []
    for constraint in constraints:
        if constraint.get('type') != 'pocket':
            continue

        binder = constraint.get('binder', 'BINDER_CHAIN')
        if binder == 'BINDER_CHAIN':
            binder = binder_chain_id

        contacts = []
        for contact in constraint.get('contacts', []):
            if not isinstance(contact, list) or len(contact) < 2:
                continue
            chain_id = contact[0]
            if chain_id == 'BINDER_CHAIN':
                chain_id = binder_chain_id
            contacts.append([chain_id, contact[1]])

        normalized.append({
            'pocket': {
                'binder': binder,
                'contacts': contacts,
                'max_distance': constraint.get('max_distance', 5.0),
                'force': constraint.get('force', False)
            }
        })

    return normalized


def _build_target_yaml_from_components(
    components: List[dict],
    constraints: List[dict],
    backend: str
) -> Tuple[str, List[str], str]:
    sequences_list = []
    chain_order = []
    chain_counter = 0

    for comp in components:
        seq = comp.get('sequence', '').strip()
        if not seq:
            continue

        comp_type = comp.get('type', 'protein')
        num_copies = max(1, int(comp.get('num_copies', 1)))

        for _ in range(num_copies):
            chain_id, chain_counter = _get_next_chain_id(chain_counter)
            chain_order.append(chain_id)

            if comp_type == 'protein':
                protein_entry = {
                    'id': chain_id,
                    'sequence': seq
                }
                if not comp.get('use_msa', True):
                    protein_entry['msa'] = 'empty'
                sequences_list.append({'protein': protein_entry})
            elif comp_type == 'dna':
                sequences_list.append({
                    'dna': {
                        'id': chain_id,
                        'sequence': seq
                    }
                })
            elif comp_type == 'rna':
                sequences_list.append({
                    'rna': {
                        'id': chain_id,
                        'sequence': seq
                    }
                })

    if not sequences_list:
        return "", [], ""

    payload = {
        'version': 1,
        'sequences': sequences_list
    }

    if backend != 'alphafold3':
        binder_chain_id = _get_chain_id_by_index(chain_counter)
        normalized_constraints = _normalize_pocket_constraints(constraints or [], binder_chain_id)
        if normalized_constraints:
            payload['constraints'] = normalized_constraints
    else:
        binder_chain_id = _get_chain_id_by_index(chain_counter)

    return yaml.dump(payload, sort_keys=False, indent=2, default_flow_style=False), chain_order, binder_chain_id


def _extract_structure_map(zip_bytes: bytes) -> dict:
    structure_map = {}
    if not zip_bytes:
        return structure_map

    with zipfile.ZipFile(io.BytesIO(zip_bytes), 'r') as zip_ref:
        for name in zip_ref.namelist():
            lower_name = name.lower()
            if not lower_name.endswith(('.cif', '.pdb')):
                continue

            parts = name.split('/')
            compound_id = None
            if 'results' in parts:
                idx = parts.index('results')
                if idx + 1 < len(parts):
                    compound_id = parts[idx + 1]

            if not compound_id:
                continue

            ext = os.path.splitext(name)[1].lower()
            prefer = compound_id not in structure_map or ext == '.cif'
            if not prefer:
                continue

            try:
                content = zip_ref.read(name).decode('utf-8', errors='ignore')
            except Exception:
                continue

            structure_map[compound_id] = {
                'content': content,
                'ext': ext or '.cif'
            }

    return structure_map


def _extract_pair_iptm_map(zip_bytes: bytes) -> dict:
    pair_map = {}
    if not zip_bytes:
        return pair_map

    with zipfile.ZipFile(io.BytesIO(zip_bytes), 'r') as zip_ref:
        for name in zip_ref.namelist():
            lower_name = name.lower()
            if not lower_name.endswith('.json'):
                continue
            if 'summary_confidences' not in lower_name and 'confidence' not in lower_name:
                continue

            parts = name.split('/')
            compound_id = None
            if 'results' in parts:
                idx = parts.index('results')
                if idx + 1 < len(parts):
                    compound_id = parts[idx + 1]

            if not compound_id:
                continue

            try:
                content = json.loads(zip_ref.read(name).decode('utf-8'))
            except Exception:
                continue

            if not isinstance(content, dict):
                continue

            if content.get("chain_pair_iptm") or content.get("pair_chains_iptm"):
                pair_map[compound_id] = content

    return pair_map


def _load_pair_iptm_from_local(task_id: str, compound_id: str) -> dict:
    if not task_id or not compound_id:
        return {}
    base_dir = os.path.join(LEAD_OPTIMIZATION_OUTPUT_DIR, task_id, "results", compound_id)
    confidence_path = os.path.join(base_dir, "confidence_data_model_0.json")
    if not os.path.exists(confidence_path):
        return {}
    try:
        with open(confidence_path, "r", encoding="utf-8") as handle:
            data = json.load(handle)
        if isinstance(data, dict) and (data.get("pair_chains_iptm") or data.get("chain_pair_iptm")):
            return data
    except Exception:
        return {}
    return {}


def _load_summary_from_local(task_id: str) -> dict:
    if not task_id:
        return {}
    summary_path = os.path.join(LEAD_OPTIMIZATION_OUTPUT_DIR, task_id, "optimization_summary.json")
    if not os.path.exists(summary_path):
        return {}
    try:
        with open(summary_path, "r", encoding="utf-8") as handle:
            data = json.load(handle)
        if isinstance(data, dict):
            return data
    except Exception:
        return {}
    return {}


def _parse_summary_from_string(payload: str) -> dict:
    if not isinstance(payload, str):
        return {}
    result = {}
    for key in ("original_compound", "strategy"):
        marker = f"{key}='"
        if marker in payload:
            value = payload.split(marker, 1)[1].split("'", 1)[0]
            result[key] = value
    if "total_candidates=" in payload:
        value = payload.split("total_candidates=", 1)[1].split(",", 1)[0]
        try:
            result["total_candidates"] = int(value)
        except ValueError:
            pass
    if "success_rate=" in payload:
        value = payload.split("success_rate=", 1)[1].split(")", 1)[0].split(",", 1)[0]
        try:
            result["success_rate"] = float(value)
        except ValueError:
            pass
    return result


def _load_log_metadata(task_id: str) -> dict:
    log_path = os.path.join(LEAD_OPTIMIZATION_OUTPUT_DIR, task_id, "lead_optimization.log")
    if not os.path.exists(log_path):
        return {}
    strategy = None
    original_compound = None
    try:
        with open(log_path, "r", encoding="utf-8") as handle:
            for line in handle:
                if "è¾“å…¥åŒ–åˆç‰©:" in line and original_compound is None:
                    original_compound = line.split("è¾“å…¥åŒ–åˆç‰©:", 1)[1].strip()
                if "ä¼˜åŒ–ç­–ç•¥:" in line and strategy is None:
                    strategy = line.split("ä¼˜åŒ–ç­–ç•¥:", 1)[1].strip()
                if original_compound and strategy:
                    break
    except Exception:
        return {}
    return {
        "original_compound": original_compound,
        "strategy": strategy
    }


def _build_summary(task_id: str, results_df: pd.DataFrame | None, raw_summary: dict) -> dict:
    summary = {}
    if raw_summary:
        summary.update(raw_summary)
        if isinstance(raw_summary.get("single_compound"), str):
            summary.update(_parse_summary_from_string(raw_summary["single_compound"]))
    summary.update({k: v for k, v in _load_log_metadata(task_id).items() if v})

    if results_df is not None and not results_df.empty:
        if "original_compound" not in summary or not summary.get("original_compound"):
            if "original_smiles" in results_df.columns:
                original_smiles = results_df["original_smiles"].dropna()
                if not original_smiles.empty:
                    summary["original_compound"] = str(original_smiles.iloc[0])

        if "total_candidates" not in summary:
            summary["total_candidates"] = len(results_df)

        if "success_rate" not in summary and "status" in results_df.columns:
            completed = int((results_df["status"] == "completed").sum())
            summary["success_rate"] = completed / len(results_df) if len(results_df) else 0.0

    return summary


def _load_results_from_zip(zip_bytes: bytes):
    summary = {}
    results_df = None

    if not zip_bytes:
        return summary, results_df, {}, {}

    with zipfile.ZipFile(io.BytesIO(zip_bytes), 'r') as zip_ref:
        names = zip_ref.namelist()
        summary_name = next((n for n in names if n.endswith("optimization_summary.json")), None)
        if summary_name:
            try:
                summary = json.loads(zip_ref.read(summary_name).decode('utf-8'))
            except Exception:
                summary = {}

        csv_name = next((n for n in names if n.endswith("optimization_results.csv")), None)
        if csv_name:
            try:
                results_df = pd.read_csv(io.BytesIO(zip_ref.read(csv_name)))
            except Exception:
                results_df = None

    structure_map = _extract_structure_map(zip_bytes)
    pair_iptm_map = _extract_pair_iptm_map(zip_bytes)
    return summary, results_df, structure_map, pair_iptm_map


def _render_smiles_2d(smiles: str):
    if not smiles:
        st.caption("âš ï¸ SMILES ä¸ºç©ºï¼Œæ— æ³•ç”Ÿæˆ2Dç»“æ„ã€‚")
        return

    try:
        from rdkit import Chem
        from rdkit.Chem import Draw
    except Exception:
        st.caption("âš ï¸ RDKit æœªå®‰è£…ï¼Œæ— æ³•æ¸²æŸ“2Dç»“æ„ã€‚")
        st.code(smiles, language="smiles")
        return

    mol = Chem.MolFromSmiles(smiles)
    if mol is None:
        st.caption("âš ï¸ æ— æ•ˆçš„SMILESï¼Œæ— æ³•ç”Ÿæˆ2Dç»“æ„ã€‚")
        st.code(smiles, language="smiles")
        return

    img = Draw.MolToImage(mol, size=(360, 240))
    st.image(img, use_container_width=False)


def render_lead_optimization_page():
    URLStateManager.restore_state_from_url()

    st.markdown("### ğŸ§ª å…ˆå¯¼åŒ–åˆç‰©ä¼˜åŒ–")
    st.markdown("åŸºäºMMPDBä¸Boltzç»“æ„é¢„æµ‹çš„å…ˆå¯¼åŒ–åˆç‰©ä¼˜åŒ–æµç¨‹ï¼Œæ”¯æŒè¿›åº¦ç›‘æ§ä¸å¯è§†åŒ–ç»“æœã€‚")

    if 'lead_optimization_task_id' not in st.session_state:
        st.session_state.lead_optimization_task_id = None
    if 'lead_optimization_results' not in st.session_state:
        st.session_state.lead_optimization_results = None
    if 'lead_optimization_error' not in st.session_state:
        st.session_state.lead_optimization_error = None
    if 'lead_optimization_raw_zip' not in st.session_state:
        st.session_state.lead_optimization_raw_zip = None
    if 'lead_optimization_components' not in st.session_state:
        st.session_state.lead_optimization_components = [{
            'id': 'protein_1',
            'type': 'protein',
            'sequence': '',
            'num_copies': 1,
            'use_msa': True
        }]
    if 'lead_optimization_constraints' not in st.session_state:
        st.session_state.lead_optimization_constraints = []
    if 'lead_optimization_backend' not in st.session_state:
        st.session_state.lead_optimization_backend = 'boltz'
    if 'lead_opt_input_method' not in st.session_state:
        st.session_state.lead_opt_input_method = 'smiles'
    if 'lead_opt_ketcher_smiles' not in st.session_state:
        st.session_state.lead_opt_ketcher_smiles = ''
    if 'lead_optimization_chain_order' not in st.session_state:
        st.session_state.lead_optimization_chain_order = []
    if 'lead_opt_pair_chain_a' not in st.session_state:
        st.session_state.lead_opt_pair_chain_a = 'B'
    if 'lead_opt_pair_chain_b' not in st.session_state:
        st.session_state.lead_opt_pair_chain_b = 'A'

    is_running = (
        st.session_state.lead_optimization_task_id is not None
        and st.session_state.lead_optimization_results is None
        and st.session_state.lead_optimization_error is None
    )

    with st.expander("ğŸ§¾ **æ­¥éª¤ 1: ä»»åŠ¡é…ç½®**", expanded=not is_running):
        target_yaml = ""

        st.markdown("**ç›®æ ‡åˆ†å­è®¾ç½®**")
        st.caption("æ”¯æŒå¤šä¸ªç»„åˆ†åºåˆ—ï¼Œç³»ç»Ÿå°†è‡ªåŠ¨åˆ†é…é“¾ IDï¼ˆé¢„ç•™ B ç»™é…ä½“ï¼‰ã€‚")

        if not st.session_state.lead_optimization_components:
            st.session_state.lead_optimization_components = [{
                'id': 'protein_1',
                'type': 'protein',
                'sequence': '',
                'num_copies': 1,
                'use_msa': True
            }]

        st.subheader("ğŸ§¬ ç›®æ ‡åˆ†å­", anchor=False)
        delete_id = None

        for idx, comp in enumerate(st.session_state.lead_optimization_components[:]):
            st.markdown("---")
            st.subheader(f"ç»„åˆ† {idx + 1}", anchor=False)

            cols_comp = st.columns([3, 1, 1])

            with cols_comp[0]:
                comp_type_options = ['protein', 'dna', 'rna']
                current_type = comp.get('type', 'protein')
                current_type_index = comp_type_options.index(current_type) if current_type in comp_type_options else 0

                old_type = current_type
                new_type = st.selectbox(
                    "ç»„åˆ†ç±»å‹",
                    options=comp_type_options,
                    format_func=lambda x: {
                        "protein": "ğŸ§¬ è›‹ç™½è´¨/è‚½é“¾",
                        "dna": "ğŸ”— DNA",
                        "rna": "ğŸ“œ RNA"
                    }[x],
                    key=f"lead_opt_type_{comp['id']}_{idx}",
                    index=current_type_index,
                    disabled=is_running,
                    help="é€‰æ‹©æ­¤ç»„åˆ†çš„åˆ†å­ç±»å‹ï¼šè›‹ç™½è´¨ã€DNA æˆ– RNAã€‚"
                )

                comp['type'] = new_type
                if new_type != old_type:
                    comp['sequence'] = ''
                    if 'use_msa' in comp:
                        del comp['use_msa']
                    if new_type == 'protein':
                        if st.session_state.lead_optimization_backend == 'alphafold3':
                            comp['use_msa'] = True
                        else:
                            comp['use_msa'] = get_smart_msa_default(st.session_state.lead_optimization_components)
                    st.rerun()

            with cols_comp[1]:
                comp['num_copies'] = st.number_input(
                    "æ‹·è´æ•°",
                    min_value=1,
                    max_value=10,
                    value=comp.get('num_copies', 1),
                    step=1,
                    key=f"lead_opt_copies_{comp['id']}_{idx}",
                    disabled=is_running,
                    help="æ­¤ç»„åˆ†çš„æ‹·è´æ•°ã€‚"
                )

            with cols_comp[2]:
                if len(st.session_state.lead_optimization_components) > 1:
                    if st.button("ğŸ—‘ï¸", key=f"lead_opt_remove_{comp['id']}_{idx}", help="åˆ é™¤æ­¤ç»„åˆ†", disabled=is_running):
                        delete_id = comp['id']

            num_copies = comp.get('num_copies', 1)
            if num_copies > 1:
                st.caption(f"ğŸ’¡ æ­¤ç»„åˆ†å°†åˆ›å»º {num_copies} ä¸ªæ‹·è´ï¼Œè‡ªåŠ¨åˆ†é…é“¾ID")

            if comp['type'] == 'protein':
                sequence_value = st.text_area(
                    "è›‹ç™½è´¨åºåˆ—",
                    value=comp.get('sequence', ''),
                    placeholder="ä¾‹å¦‚: MVSKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLV...",
                    disabled=is_running,
                    height=100,
                    key=f"lead_opt_seq_{comp['id']}_{idx}",
                    help="è¾“å…¥æ­¤è›‹ç™½è´¨é“¾çš„å®Œæ•´æ°¨åŸºé…¸åºåˆ—ã€‚"
                )
                comp['sequence'] = sequence_value

                if comp.get('sequence', '').strip():
                    msa_disabled = is_running or st.session_state.lead_optimization_backend == 'alphafold3'
                    msa_help = "AlphaFold3 å¼•æ“è¦æ±‚ä¸ºæ‰€æœ‰è›‹ç™½è´¨ç”Ÿæˆ MSAï¼Œå·²è‡ªåŠ¨å¯ç”¨å¹¶é”å®šã€‚" if st.session_state.lead_optimization_backend == 'alphafold3' else "ä¸ºæ­¤è›‹ç™½è´¨ç»„åˆ†ç”Ÿæˆå¤šåºåˆ—æ¯”å¯¹ä»¥æé«˜é¢„æµ‹ç²¾åº¦ã€‚å–æ¶ˆå‹¾é€‰å¯ä»¥è·³è¿‡MSAç”Ÿæˆï¼ŒèŠ‚çœæ—¶é—´ã€‚"
                    msa_value = st.checkbox(
                        "å¯ç”¨ MSA",
                        value=True if st.session_state.lead_optimization_backend == 'alphafold3' else comp.get('use_msa', True),
                        key=f"lead_opt_msa_{comp['id']}_{idx}",
                        help=msa_help,
                        disabled=msa_disabled
                    )
                    if st.session_state.lead_optimization_backend == 'alphafold3':
                        comp['use_msa'] = True
                    elif msa_value != comp.get('use_msa', True):
                        comp['use_msa'] = msa_value
                        st.rerun()
                else:
                    if st.session_state.lead_optimization_backend == 'alphafold3':
                        comp['use_msa'] = True

            elif comp['type'] in ['dna', 'rna']:
                seq_type = "DNA" if comp['type'] == 'dna' else "RNA"
                placeholder = "ATGCGTAAGGGATCCGCATGC..." if comp['type'] == 'dna' else "AUGCGUAAGGAUCCGCAUGC..."
                sequence_value = st.text_area(
                    f"{seq_type}åºåˆ—",
                    value=comp.get('sequence', ''),
                    placeholder=f"ä¾‹å¦‚: {placeholder}",
                    disabled=is_running,
                    height=100,
                    key=f"lead_opt_seq_{comp['id']}_{idx}",
                    help=f"è¾“å…¥{seq_type}æ ¸è‹·é…¸åºåˆ—ã€‚"
                )
                comp['sequence'] = sequence_value

        if delete_id:
            st.session_state.lead_optimization_components = [
                comp for comp in st.session_state.lead_optimization_components if comp['id'] != delete_id
            ]
            st.rerun()

        if st.button(
            "â• æ·»åŠ æ–°ç»„åˆ†",
            key="add_lead_opt_component",
            disabled=is_running,
            use_container_width=True,
            help="æ·»åŠ æ–°çš„ç»„åˆ†"
        ):
            next_index = len(st.session_state.lead_optimization_components) + 1
            default_use_msa = True if st.session_state.lead_optimization_backend == 'alphafold3' else get_smart_msa_default(
                st.session_state.lead_optimization_components
            )
            st.session_state.lead_optimization_components.append({
                'id': f'protein_{next_index}',
                'type': 'protein',
                'sequence': '',
                'num_copies': 1,
                'use_msa': default_use_msa
            })
            st.rerun()

        backend_options = list(BACKEND_LABELS.keys())
        current_backend = st.session_state.lead_optimization_backend
        if current_backend not in backend_options:
            current_backend = 'boltz'

        selected_backend = st.selectbox(
            "é€‰æ‹©é¢„æµ‹åç«¯",
            backend_options,
            index=backend_options.index(current_backend),
            format_func=lambda key: BACKEND_LABELS.get(key, key),
            disabled=is_running,
            help="Boltz å¼•æ“æ”¯æŒå£è¢‹çº¦æŸï¼›AlphaFold3 ä¸æ”¯æŒçº¦æŸè®¾ç½®ã€‚"
        )

        if selected_backend != current_backend:
            st.session_state.lead_optimization_backend = selected_backend
            if selected_backend == 'alphafold3':
                for comp in st.session_state.lead_optimization_components:
                    if comp.get('type') == 'protein':
                        comp['use_msa'] = True
            st.rerun()

        chain_ids, chain_descriptions = _get_chain_ids_for_components(
            st.session_state.lead_optimization_components
        )
        binder_chain_id = _get_chain_id_by_index(len(chain_ids))
        available_chains = chain_ids + ['BINDER_CHAIN']
        chain_descriptions['BINDER_CHAIN'] = f"ğŸ¯ ç»“åˆåˆ†å­ (å°†åˆ†é…é“¾ {binder_chain_id})"
        target_chain_ids = chain_ids
        default_target_chain = target_chain_ids[0] if target_chain_ids else 'A'

        st.subheader("ğŸ§· é“¾å¯¹è®¾ç½®", anchor=False)
        st.caption("ç”¨äºå®šä¹‰ç»“åˆé“¾å¯¹ã€é»˜è®¤å£è¢‹çº¦æŸç›®æ ‡ï¼Œå¹¶ç”¨äº pair ipTM å±•ç¤ºã€‚")

        cols_pair = st.columns([1, 2])
        with cols_pair[0]:
            st.selectbox(
                "è®¾è®¡é“¾",
                options=[binder_chain_id],
                index=0,
                disabled=True,
                help="å…ˆå¯¼åŒ–åˆç‰©å›ºå®šä¸ºè®¾è®¡é“¾"
            )
            st.session_state.lead_opt_pair_chain_a = binder_chain_id

        with cols_pair[1]:
            if target_chain_ids:
                current_target_chain = st.session_state.lead_opt_pair_chain_b
                if current_target_chain not in target_chain_ids:
                    current_target_chain = default_target_chain
                target_chain = st.selectbox(
                    "è¢«ç»“åˆé“¾",
                    options=target_chain_ids,
                    index=target_chain_ids.index(current_target_chain),
                    format_func=lambda c: chain_descriptions.get(c, c),
                    disabled=is_running
                )
                st.session_state.lead_opt_pair_chain_b = target_chain
            else:
                st.selectbox(
                    "è¢«ç»“åˆé“¾",
                    options=["A"],
                    index=0,
                    disabled=True
                )
                st.session_state.lead_opt_pair_chain_b = "A"

        default_target_chain = st.session_state.lead_opt_pair_chain_b or default_target_chain

        st.subheader("ğŸ”— åˆ†å­çº¦æŸ (å¯é€‰)", anchor=False)
        if selected_backend == 'alphafold3':
            st.info("AlphaFold3 åç«¯æš‚ä¸æ”¯æŒçº¦æŸè®¾ç½®ï¼Œè¯·åˆ‡æ¢å› Boltz å¼•æ“ã€‚", icon="â„¹ï¸")

        constraints_disabled = is_running or selected_backend == 'alphafold3'
        constraint_id_to_delete = None

        for i, constraint in enumerate(st.session_state.lead_optimization_constraints[:]):
            with st.expander(f"ğŸ•³ï¸ Pocket çº¦æŸ {i+1}", expanded=True):
                col1, col2 = st.columns([5, 1])
                with col1:
                    render_pocket_constraint_ui(
                        constraint,
                        f"lead_opt_{i}",
                        available_chains,
                        chain_descriptions,
                        constraints_disabled,
                        components=st.session_state.lead_optimization_components
                    )
                with col2:
                    if st.button("ğŸ—‘ï¸", key=f"lead_opt_del_constraint_{i}", help="åˆ é™¤æ­¤çº¦æŸ", disabled=constraints_disabled):
                        constraint_id_to_delete = i

        if constraint_id_to_delete is not None:
            del st.session_state.lead_optimization_constraints[constraint_id_to_delete]
            st.rerun()

        if st.button(
            "â• æ·»åŠ  Pocket çº¦æŸ",
            key="add_lead_opt_pocket_constraint",
            disabled=constraints_disabled or not target_chain_ids
        ):
            st.session_state.lead_optimization_constraints.append({
                'type': 'pocket',
                'binder': 'BINDER_CHAIN',
                'contacts': [[default_target_chain, 1], [default_target_chain, 2]],
                'max_distance': 5.0,
                'force': False
            })
            st.rerun()

        target_yaml, chain_order, binder_chain_id = _build_target_yaml_from_components(
            st.session_state.lead_optimization_components,
            st.session_state.lead_optimization_constraints,
            selected_backend
        )
        if chain_order:
            st.session_state.lead_optimization_chain_order = chain_order + [binder_chain_id]
            st.session_state.lead_opt_pair_chain_a = binder_chain_id
        else:
            st.session_state.lead_optimization_chain_order = []

        st.divider()

        st.markdown("**å…ˆå¯¼åŒ–åˆç‰©è¾“å…¥**")
        input_mode = st.radio(
            "è¾“å…¥æ¨¡å¼",
            ["å•ä¸ª", "æ‰¹é‡æ–‡ä»¶"],
            horizontal=True,
            disabled=is_running
        )

        input_compound = ""
        input_file = None

        if input_mode == "å•ä¸ª":
            method_options = ["smiles", "ketcher"]
            new_input_method = st.radio(
                "è¾“å…¥æ–¹æ³•",
                method_options,
                index=method_options.index(st.session_state.get('lead_opt_input_method', 'smiles')),
                disabled=is_running,
                horizontal=True
            )
            st.session_state.lead_opt_input_method = new_input_method

            if new_input_method == "smiles":
                input_compound = st.text_input(
                    "è¾“å…¥å…ˆå¯¼åŒ–åˆç‰© SMILES",
                    placeholder="ä¾‹å¦‚: CN1CCN(CC1)c2ccc(cc2)n3c5c(cn3)cnc(c4c(cccc4F)OC)c5",
                    disabled=is_running
                )
            else:
                from streamlit_ketcher import st_ketcher

                initial_smiles = st.session_state.get('lead_opt_ketcher_smiles', '')
                st.info("åœ¨ä¸‹æ–¹ **Ketcher ç¼–è¾‘å™¨** ä¸­ç»˜åˆ¶åˆ†å­ï¼Œæˆ–ç›´æ¥ç²˜è´´ SMILES å­—ç¬¦ä¸²ã€‚å®Œæˆåç‚¹å‡»ç¼–è¾‘å™¨å†…çš„ Applyã€‚", icon="ğŸ’¡")
                ketcher_smiles = st_ketcher(
                    value=initial_smiles,
                    key="lead_opt_ketcher",
                    height=400
                )
                if ketcher_smiles is not None:
                    ketcher_smiles = ketcher_smiles.strip()
                st.session_state.lead_opt_ketcher_smiles = ketcher_smiles
                input_compound = ketcher_smiles

                st.markdown("<hr style='margin-top: 0.5rem; margin-bottom: 0.5rem'>", unsafe_allow_html=True)
                st.caption("âœ¨ Ketcher ç”Ÿæˆçš„ SMILES å­—ç¬¦ä¸²:")
                current_smiles = st.session_state.get('lead_opt_ketcher_smiles', '')
                if current_smiles:
                    st.code(current_smiles, language='smiles')
                else:
                    st.info("ğŸ‘† è¯·å¼€å§‹ç»˜åˆ¶æˆ–ç²˜è´´ï¼ŒSMILES å°†ä¼šæ˜¾ç¤ºåœ¨è¿™é‡Œã€‚")
        else:
            input_file = st.file_uploader(
                "ä¸Šä¼  SMILES æ–‡ä»¶ (CSV/SMI/TXT)",
                type=['csv', 'smi', 'smiles', 'txt'],
                disabled=is_running
            )

        with st.expander("âš™ï¸ **ç‚¹å‡»è®¾ç½®ï¼šä¼˜åŒ–å‚æ•°**", expanded=False):
            col1, col2 = st.columns(2)

            with col1:
                optimization_strategy = st.selectbox(
                    "ä¼˜åŒ–ç­–ç•¥",
                    ["scaffold_hopping", "fragment_replacement", "multi_objective"],
                    disabled=is_running
                )
                max_candidates = st.number_input(
                    "æ¯è½®æœ€å¤§å€™é€‰æ•°",
                    min_value=1,
                    max_value=500,
                    value=30,
                    step=1,
                    disabled=is_running
                )
                iterations = st.number_input(
                    "è¿­ä»£è½®æ•°",
                    min_value=1,
                    max_value=20,
                    value=1,
                    step=1,
                    disabled=is_running
                )
                batch_size = st.number_input(
                    "æ‰¹æ¬¡å¤§å°",
                    min_value=1,
                    max_value=32,
                    value=4,
                    step=1,
                    disabled=is_running
                )

            with col2:
                top_k_per_iteration = st.number_input(
                    "æ¯è½®ä¿ç•™ Top K",
                    min_value=1,
                    max_value=50,
                    value=5,
                    step=1,
                    disabled=is_running
                )
                diversity_weight = st.slider(
                    "å¤šæ ·æ€§æƒé‡",
                    min_value=0.0,
                    max_value=1.0,
                    value=0.3,
                    step=0.05,
                    disabled=is_running
                )
                similarity_threshold = st.slider(
                    "æœ€å°ç›¸ä¼¼æ€§",
                    min_value=0.0,
                    max_value=1.0,
                    value=0.5,
                    step=0.05,
                    disabled=is_running
                )
                max_similarity_threshold = st.slider(
                    "æœ€å¤§ç›¸ä¼¼æ€§",
                    min_value=0.0,
                    max_value=1.0,
                    value=0.9,
                    step=0.05,
                    disabled=is_running
                )

            diversity_selection_strategy = st.selectbox(
                "å¤šæ ·æ€§é€‰æ‹©ç­–ç•¥",
                ["tanimoto_diverse", "scaffold_diverse", "property_diverse", "hybrid"],
                disabled=is_running
            )

            limit_chiral = st.checkbox(
                "é™åˆ¶æœ€å¤§æ‰‹æ€§ä¸­å¿ƒæ•°",
                value=False,
                disabled=is_running
            )
            max_chiral_centers = None
            if limit_chiral:
                max_chiral_centers = st.number_input(
                    "æœ€å¤§æ‰‹æ€§ä¸­å¿ƒæ•°",
                    min_value=1,
                    max_value=20,
                    value=4,
                    step=1,
                    disabled=is_running
                )

            generate_report = st.checkbox(
                "ç”ŸæˆHTMLæŠ¥å‘Š",
                value=False,
                disabled=is_running
            )

        can_submit = bool(target_yaml.strip()) and (
            (input_mode == "å•ä¸ª" and input_compound.strip()) or
            (input_mode == "æ‰¹é‡æ–‡ä»¶" and input_file is not None)
        )

        if st.button(
            "ğŸš€ å¼€å§‹ä¼˜åŒ–",
            type="primary",
            disabled=is_running or not can_submit,
            use_container_width=True
        ):
            st.session_state.lead_optimization_task_id = None
            st.session_state.lead_optimization_results = None
            st.session_state.lead_optimization_error = None
            st.session_state.lead_optimization_raw_zip = None

            options = {
                'optimization_strategy': optimization_strategy,
                'max_candidates': int(max_candidates),
                'iterations': int(iterations),
                'batch_size': int(batch_size),
                'top_k_per_iteration': int(top_k_per_iteration),
                'diversity_weight': float(diversity_weight),
                'similarity_threshold': float(similarity_threshold),
                'max_similarity_threshold': float(max_similarity_threshold),
                'diversity_selection_strategy': diversity_selection_strategy,
                'max_chiral_centers': int(max_chiral_centers) if max_chiral_centers else None,
                'generate_report': generate_report,
                'backend': st.session_state.lead_optimization_backend
            }

            try:
                if input_mode == "æ‰¹é‡æ–‡ä»¶" and input_file is not None:
                    task_id = submit_lead_optimization(
                        target_config_content=target_yaml,
                        input_filename=input_file.name,
                        input_file_content=input_file.getvalue(),
                        options=options
                    )
                else:
                    task_id = submit_lead_optimization(
                        target_config_content=target_yaml,
                        input_compound=input_compound.strip(),
                        options=options
                    )

                st.session_state.lead_optimization_task_id = task_id
                URLStateManager.update_url_for_lead_optimization_config(
                    task_id=task_id,
                    components=st.session_state.lead_optimization_components,
                    constraints=st.session_state.lead_optimization_constraints,
                    backend=st.session_state.lead_optimization_backend,
                    pair_chain_a=st.session_state.lead_opt_pair_chain_a,
                    pair_chain_b=st.session_state.lead_opt_pair_chain_b
                )
                st.success(f"âœ… ä»»åŠ¡å·²æäº¤ï¼ŒID: {task_id[:8]}...")
                st.rerun()
            except Exception as e:
                st.session_state.lead_optimization_error = {"error_message": str(e), "type": "Submit Error"}
                st.error(f"âŒ æäº¤ä»»åŠ¡å¤±è´¥: {e}")

    if is_running:
        st.divider()
        col_title, col_stop = st.columns([3, 2])
        with col_title:
            st.header("ğŸ”„ **æ­¥éª¤ 2: è¿›åº¦ç›‘æ§**", anchor=False)
        with col_stop:
            st.markdown("""
            <style>
            .stop-button {
                background: linear-gradient(135deg, #ff6b6b, #ee5a52);
                border: none;
                border-radius: 12px;
                color: white;
                padding: 10px 20px;
                font-size: 14px;
                font-weight: 600;
                cursor: pointer;
                transition: all 0.3s ease;
                box-shadow: 0 4px 12px rgba(255, 107, 107, 0.3);
                width: 100%;
                text-align: center;
                margin-top: 8px;
            }
            .stop-button:hover {
                background: linear-gradient(135deg, #ff5252, #d32f2f);
                transform: translateY(-2px);
                box-shadow: 0 6px 16px rgba(255, 107, 107, 0.4);
            }
            </style>
            """, unsafe_allow_html=True)
            if st.button(
                "ğŸ›‘ ç´§æ€¥åœæ­¢",
                type="secondary",
                use_container_width=True,
                help="å®‰å…¨ç»ˆæ­¢æ­£åœ¨è¿›è¡Œçš„ä¼˜åŒ–ä»»åŠ¡",
                key="stop_lead_opt_btn"
            ):
                try:
                    terminate_task(st.session_state.lead_optimization_task_id)
                    st.info("ğŸ”„ å·²å‘é€åœæ­¢ä¿¡å·ï¼Œç­‰å¾…ä»»åŠ¡ç»ˆæ­¢...")
                    st.session_state.lead_optimization_task_id = None
                    st.session_state.lead_optimization_results = None
                    st.session_state.lead_optimization_error = {"error_message": "ç”¨æˆ·æ‰‹åŠ¨åœæ­¢ä»»åŠ¡", "type": "User Cancelled"}
                    URLStateManager.clear_url_params()
                    st.rerun()
                except Exception as e:
                    st.error(f"âŒ åœæ­¢ä»»åŠ¡å¤±è´¥: {e}")
                    st.session_state.lead_optimization_error = {"error_message": str(e), "type": "Stop Error"}

        try:
            status_data = get_lead_optimization_status(st.session_state.lead_optimization_task_id)
            state = status_data.get('state', 'UNKNOWN')
            progress = status_data.get('progress', {}) or {}

            if state in ['SUCCESS', 'COMPLETED']:
                st.success("ğŸ‰ å…ˆå¯¼ä¼˜åŒ–ä»»åŠ¡å·²å®Œæˆï¼Œæ­£åœ¨åŠ è½½ç»“æœ...")
                raw_zip = download_lead_optimization_results(st.session_state.lead_optimization_task_id)
                summary, results_df, structure_map, pair_iptm_map = _load_results_from_zip(raw_zip)
                st.session_state.lead_optimization_results = {
                    "summary": summary,
                    "results_df": results_df,
                    "structure_map": structure_map,
                    "pair_iptm_map": pair_iptm_map
                }
                st.session_state.lead_optimization_raw_zip = raw_zip
                st.rerun()
            elif state in ['FAILURE', 'REVOKED']:
                error_msg = status_data.get('error', 'ä»»åŠ¡å¤±è´¥')
                st.session_state.lead_optimization_error = {"error_message": error_msg, "type": "Task Error"}
                st.error(f"âŒ ä»»åŠ¡å¤±è´¥: {error_msg}")
            else:
                progress_percent = progress.get('progress_percent')
                if progress_percent is None:
                    processed = progress.get('processed_candidates', 0)
                    expected = progress.get('expected_candidates') or progress.get('total_compounds') or 0
                    if expected:
                        progress_percent = min(processed / expected * 100, 100.0)

                if progress_percent is not None:
                    st.progress(min(max(progress_percent / 100.0, 0.0), 1.0),
                                text=f"æ€»ä½“è¿›åº¦: {progress_percent:.1f}%")

                col1, col2, col3 = st.columns(3)
                col1.metric("å·²å¤„ç†å€™é€‰", progress.get('processed_candidates', progress.get('completed_compounds', 0)))
                col2.metric("é¢„è®¡å€™é€‰", progress.get('expected_candidates', progress.get('total_compounds', 0)) or "æœªçŸ¥")
                col3.metric("å‰©ä½™ä¼°è®¡ (ç§’)", int(progress.get('estimated_remaining_seconds', 0) or 0))

                if progress.get('estimated_completion_time'):
                    st.caption(f"é¢„è®¡å®Œæˆæ—¶é—´: {progress.get('estimated_completion_time')}")

                st.caption("ğŸ”„ é¡µé¢å°†è‡ªåŠ¨åˆ·æ–°ä»¥è·å–æœ€æ–°è¿›åº¦â€¦")
                time.sleep(5)
                st.rerun()
        except Exception as e:
            st.session_state.lead_optimization_error = {"error_message": str(e), "type": "Status Error"}
            st.error(f"âŒ è·å–çŠ¶æ€å¤±è´¥: {e}")

    if st.session_state.lead_optimization_error and not is_running:
        error_info = st.session_state.lead_optimization_error
        st.error(f"âŒ ä»»åŠ¡é”™è¯¯: {error_info.get('error_message', 'æœªçŸ¥é”™è¯¯')}")

    if st.session_state.lead_optimization_results:
        st.divider()
        st.header("ğŸ† **æ­¥éª¤ 3: ä¼˜åŒ–ç»“æœå±•ç¤º**", anchor=False)

        results = st.session_state.lead_optimization_results
        results_df = results.get("results_df")
        summary = results.get("summary", {})
        if not summary:
            summary = _load_summary_from_local(st.session_state.lead_optimization_task_id)
        summary = _build_summary(st.session_state.lead_optimization_task_id, results_df, summary)
        structure_map = results.get("structure_map", {})
        pair_iptm_map = results.get("pair_iptm_map", {})
        chain_order = st.session_state.get("lead_optimization_chain_order", [])
        target_chain = st.session_state.get("lead_opt_pair_chain_b", chain_order[0] if chain_order else "A")
        ligand_chain = st.session_state.get("lead_opt_pair_chain_a", "B")

        if st.session_state.lead_optimization_raw_zip:
            st.download_button(
                label="ğŸ“¦ ä¸‹è½½å®Œæ•´ç»“æœ (ZIP)",
                data=st.session_state.lead_optimization_raw_zip,
                file_name=f"{st.session_state.lead_optimization_task_id}_lead_optimization_results.zip",
                mime="application/zip",
                use_container_width=True
            )

        if summary:
            st.subheader("ğŸ“Š ç»“æœæ‘˜è¦", anchor=False)
            col1, col2 = st.columns(2)
            col1.metric("æ€»å€™é€‰æ•°", summary.get('total_candidates', summary.get('total_compounds', 'N/A')))
            success_rate = summary.get('success_rate')
            if isinstance(success_rate, str):
                try:
                    success_rate = float(success_rate)
                except ValueError:
                    success_rate = None
            success_rate_display = f"{success_rate:.2%}" if isinstance(success_rate, float) else "N/A"
            col2.metric("æˆåŠŸç‡", success_rate_display)
        elif results_df is not None and not results_df.empty:
            st.subheader("ğŸ“Š ç»“æœæ‘˜è¦", anchor=False)
            total_candidates = len(results_df)
            completed = 0
            if 'status' in results_df.columns:
                completed = int((results_df['status'] == 'completed').sum())
            success_rate = (completed / total_candidates) if total_candidates else 0
            col1, col2, col3, col4 = st.columns(4)
            col1.metric("åŸå§‹åŒ–åˆç‰©", "N/A")
            col2.metric("ç­–ç•¥", "N/A")
            col3.metric("æ€»å€™é€‰æ•°", total_candidates)
            col4.metric("æˆåŠŸç‡", f"{success_rate:.2%}")

        if results_df is None or results_df.empty:
            st.info("æš‚æ— å¯ç”¨ç»“æœæ•°æ®ã€‚è¯·æ£€æŸ¥è¾“å‡ºæ–‡ä»¶æ˜¯å¦å®Œæ•´ã€‚")
            return

        filtered_df = results_df.copy()
        if 'combined_score' in filtered_df.columns:
            filtered_df['combined_score'] = pd.to_numeric(filtered_df['combined_score'], errors='coerce')
        if 'status' in filtered_df.columns:
            filtered_df = filtered_df[filtered_df['status'] == 'completed']

        with st.expander("ğŸ›ï¸ **ç»“æœè¿‡æ»¤è®¾ç½®**", expanded=False):
            min_score = st.slider("ç»¼åˆè¯„åˆ†é˜ˆå€¼", 0.0, 1.0, 0.6, 0.05)
            max_display = st.slider("æœ€å¤§å±•ç¤ºæ•°é‡", 5, 100, 10, 1)

        if 'combined_score' in filtered_df.columns:
            filtered_df = filtered_df[filtered_df['combined_score'] >= min_score]
            filtered_df = filtered_df.sort_values(by='combined_score', ascending=False)

        top_df = filtered_df.head(max_display)

        st.subheader("ğŸ¥‡ ä¼˜åŒ–å€™é€‰åˆ—è¡¨", anchor=False)

        if top_df.empty:
            st.warning("æœªæ‰¾åˆ°æ»¡è¶³æ¡ä»¶çš„å€™é€‰åŒ–åˆç‰©ã€‚")
            return

        for idx, row in top_df.reset_index(drop=True).iterrows():
            rank = idx + 1
            compound_id = str(row.get('compound_id', f"candidate_{rank}"))
            smiles = row.get('optimized_smiles', '')
            score = row.get('combined_score', 0.0) if pd.notna(row.get('combined_score', None)) else 0.0

            score_color = "ğŸŸ¢" if score >= 0.8 else "ğŸŸ¡" if score >= 0.7 else "ğŸŸ "

            with st.expander(f"**ç¬¬ {rank} å** {score_color} è¯„åˆ†: {score:.3f}", expanded=(idx < 3)):
                col_smiles, col_structure = st.columns([1.4, 1])
                with col_smiles:
                    st.markdown("**SMILES**")
                    st.code(smiles, language="smiles")
                with col_structure:
                    st.markdown("**2D ç»“æ„**")
                    _render_smiles_2d(smiles)

                col_metrics = st.columns(4)
                col_metrics[0].metric("ç»¼åˆè¯„åˆ†", f"{score:.3f}")
                col_metrics[1].metric("binding_probability", row.get('binding_probability', 'N/A'))
                col_metrics[2].metric("pLDDT", row.get('plddt', 'N/A'))

                pair_iptm_value = None
                pair_data = pair_iptm_map.get(compound_id, {})
                if not pair_data:
                    pair_data = _load_pair_iptm_from_local(
                        st.session_state.lead_optimization_task_id,
                        compound_id
                    )

                if pair_data:
                    inferred_chain_order = chain_order
                    if not inferred_chain_order and isinstance(pair_data.get("pair_chains_iptm"), dict):
                        size = len(pair_data["pair_chains_iptm"])
                        inferred_chain_order = [
                            _get_chain_id_by_index(i) for i in range(size)
                        ]

                    display_ligand_chain = ligand_chain
                    display_target_chain = target_chain
                    if inferred_chain_order:
                        if display_ligand_chain not in inferred_chain_order:
                            display_ligand_chain = inferred_chain_order[-1]
                        if display_target_chain not in inferred_chain_order:
                            display_target_chain = inferred_chain_order[0]

                    pair_iptm_value = get_pair_iptm_from_confidence(
                        pair_data,
                        display_ligand_chain,
                        display_target_chain,
                        chain_order=inferred_chain_order or None
                    )

                pair_iptm_display = f"{pair_iptm_value:.3f}" if isinstance(pair_iptm_value, (int, float)) else "N/A"
                col_metrics[3].metric("pair ipTM", pair_iptm_display)

                if compound_id in structure_map:
                    structure = structure_map[compound_id]
                    ext = structure.get('ext', '.cif')
                    content = structure.get('content', '')

                    col_download = st.columns(2)
                    with col_download[0]:
                        mime_type = "chemical/x-pdb" if ext == '.pdb' else "chemical/x-cif"
                        st.download_button(
                            label=f"ğŸ“„ ä¸‹è½½ç»“æ„ ({ext.upper().lstrip('.')})",
                            data=content,
                            file_name=f"{compound_id}{ext}",
                            mime=mime_type,
                            use_container_width=True,
                            key=f"download_structure_{compound_id}"
                        )

                    with col_download[1]:
                        if st.button(
                            "ğŸ”¬ æŸ¥çœ‹ç›¸äº’ä½œç”¨",
                            use_container_width=True,
                            key=f"view_interaction_{compound_id}"
                        ):
                            st.session_state[f"show_interaction_{compound_id}"] = not st.session_state.get(
                                f"show_interaction_{compound_id}", False
                            )
                            st.rerun()

                    if st.session_state.get(f"show_interaction_{compound_id}", False):
                        st.markdown("---")
                        st.markdown("**ğŸ”¬ 3Dç»“æ„ä¸ç›¸äº’ä½œç”¨**")

                        if ext != '.cif':
                            st.caption("âš ï¸ å½“å‰ä»…æ”¯æŒ CIF ç»“æ„çš„3Då±•ç¤ºã€‚")
                        else:
                            try:
                                structure_obj = read_cif_from_string(content)
                                residue_bfactors = extract_protein_residue_bfactors(structure_obj)
                                view_html = visualize_structure_py3dmol(
                                    cif_content=content,
                                    residue_bfactors=residue_bfactors,
                                    protein_style='cartoon',
                                    ligand_style='ball-and-stick',
                                    spin=False,
                                    color_scheme='pLDDT'
                                )
                                st.components.v1.html(view_html, height=500, scrolling=False)
                            except Exception as e:
                                st.error(f"âŒ 3Dç»“æ„æ˜¾ç¤ºå¤±è´¥: {e}")
                else:
                    st.caption("âš ï¸ æœªæ‰¾åˆ°è¯¥å€™é€‰çš„ç»“æ„æ–‡ä»¶ã€‚")
