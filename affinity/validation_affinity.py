import os
import json
import pandas as pd
import requests
import time
import zipfile
import tempfile
from io import BytesIO
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
import re
import math
import csv
from pathlib import Path

def delta_g_to_pIC50(delta_g_kcal_mol):
    """
    å°† FEP çš„ Î”G (kcal/mol) è½¬æ¢ä¸º pIC50
    Î”G = -RT * ln(Kd)
    Kd (M) = exp(-Î”G / (RT))
    å…¶ä¸­ R = 0.001987 kcal/(molÂ·K), T = 298.15 K
    RT = 0.5926 kcal/mol
    pIC50 = -log10(Kd) = -log10(exp(-Î”G / RT)) = Î”G / (RT * ln(10)) = Î”G / (0.5926 * 2.303) = Î”G / 1.364
    """
    try:
        dg = float(delta_g_kcal_mol)
        RT = 0.5926  # kcal/mol at 298.15 K
        ln10 = 2.303
        pIC50 = -dg / (RT * ln10)  # æ³¨æ„ FEP çš„ Î”G é€šå¸¸æ˜¯è´Ÿå€¼ï¼ˆç»“åˆæœ‰åˆ©ï¼‰
        return pIC50
    except (ValueError, TypeError):
        return None

# =========================
# SDF å®éªŒå€¼ -> pIC50
# =========================
def safe_float(x):
    try:
        return float(str(x).strip())
    except:
        return None

def to_pIC50_from_uM(x_uM):
    x = safe_float(x_uM)
    if x is None or x <= 0:
        return None
    return 6.0 - math.log10(x)

def to_M(val, unit_hint):
    v = safe_float(val)
    if v is None or v <= 0:
        return None
    if not unit_hint:
        return None
    u = unit_hint.strip().lower()
    if u == 'um':
        return v * 1e-6
    if u == 'nm':
        return v * 1e-9
    return None

def detect_unit_from_fieldname(field):
    f = field.lower()
    if ('[um]' in f) or ('_um' in f) or (' kd_um' in f) or (' ic50_um' in f) or (' um' in f):
        return 'uM'
    if ('[nm]' in f) or ('_nm' in f) or (' kd_nm' in f) or (' ic50_nm' in f) or (' nm' in f):
        return 'nM'
    return None

def parse_sdf_plain(sdf_path):
    molecules, props, order = [], {}, 0
    field_name = None
    with open(sdf_path, 'r', encoding='utf-8', errors='ignore') as f:
        for line in f:
            line = line.rstrip('\n')
            if line == '$$$$':
                if props:
                    props['___order'] = order
                    molecules.append(props)
                    order += 1
                props, field_name = {}, None
                continue
            m = re.match(r'^\s*>\s*<([^>]+)>\s*$', line)
            if m:
                field_name = m.group(1).strip()
                props.setdefault(field_name, [])
                continue
            if field_name is not None:
                if line.strip() == '':
                    field_name = None
                else:
                    props[field_name].append(line)
    if props:
        props['___order'] = order
        molecules.append(props)
    for p in molecules:
        for k, v in list(p.items()):
            if k == '___order':
                continue
            if isinstance(v, list):
                p[k] = ' '.join(v).strip()
    return molecules

PREFERRED_NAME_FIELDS = ['Name','name','MOLNAME','MoleculeName','Compound_Name','Title','ID','MolID']
CANDIDATE_EXP_FIELDS = [
    'IC50[uM]','IC50[nM]','IC50[uM](SPA)',
    'IC50 uM', 'IC50 nM',  # æ·»åŠ å¯¹ç©ºæ ¼çš„æ”¯æŒ
    'Protein/Binding/ITC_Mean_KD_uM_HIF2a_240-350_human;(Num)',
    'KD[uM]','KD[nM]','Ki[uM]','Ki[nM]',
    'IC50','KD','Ki'
]

def pick_name(props):
    for k in PREFERRED_NAME_FIELDS:
        if k in props and str(props[k]).strip():
            return props[k].strip()
    for k in props.keys():
        if k.lower() == 'name' and str(props[k]).strip():
            return props[k].strip()
    return f"mol_{props.get('___order','na')}"

def parse_exp_from_props(props):
    # ä¼˜å…ˆæŒ‰å€™é€‰å­—æ®µ
    for field in CANDIDATE_EXP_FIELDS:
        if field in props and str(props[field]).strip():
            raw = props[field].strip()
            unit = detect_unit_from_fieldname(field)
            m = re.match(r'^\s*([0-9.eE+-]+)\s*([un]M)?\s*$', raw)
            if m:
                val = m.group(1); val_unit = m.group(2)
                if unit is None and val_unit:
                    unit = val_unit
                exp_M = to_M(val, unit)
                if exp_M is not None:
                    return exp_M, field, raw, unit or 'Unknown'
            else:
                val = safe_float(raw)
                if val is not None and val > 0 and unit is not None:
                    exp_M = to_M(val, unit)
                    if exp_M is not None:
                        return exp_M, field, raw, unit or 'Unknown'
    # å…œåº•ï¼šæ‰«ææ‰€æœ‰å«å•ä½çš„å­—æ®µ
    for k, v in props.items():
        if k == '___order': 
            continue
        unit = detect_unit_from_fieldname(k)
        if unit is None:
            continue
        m = re.match(r'^\s*([0-9.eE+-]+)\s*([un]M)?\s*$', str(v).strip())
        if m:
            val = m.group(1); val_unit = m.group(2)
            if unit is None and val_unit:
                unit = val_unit
            exp_M = to_M(val, unit)
            if exp_M is not None:
                return exp_M, k, str(v).strip(), unit or 'Unknown'
    return None, None, None, None

def load_sdf_pIC50_map(ligands_sdf_path, override_name_field=None):
    """
    è¿”å›ï¼š
      exp_map: {Name: {'pIC50_exp': float, 'exp_raw': str, 'exp_field': str, 'exp_unit': str}}
    """
    mols = parse_sdf_plain(ligands_sdf_path)
    exp_map = {}
    for props in mols:
        name = (props.get(override_name_field, '').strip() if override_name_field and props.get(override_name_field)
                else pick_name(props))
        exp_M, field_used, raw_str, unit_used = parse_exp_from_props(props)
        pIC50 = (-math.log10(exp_M)) if (exp_M and exp_M > 0) else None
        exp_map[name] = {
            'pIC50_exp': pIC50,
            'exp_raw': raw_str,
            'exp_field': field_used,
            'exp_unit': unit_used
        }
    return exp_map

# =========================
# ä½ åŸæ¥çš„ä»£ç ï¼ˆä¿ç•™/æ”¹é€ ï¼‰
# =========================
def check_server_status():
    try:
        health_url = "http://127.0.0.1:5000/monitor/health"
        response = requests.get(health_url, timeout=5)
        server_healthy = response.status_code == 200
        monitor_status = None
        try:
            api_token = os.environ.get('API_SECRET_TOKEN')
            headers = {"X-API-Token": api_token} if api_token else {}
            monitor_url = "http://127.0.0.1:5000/monitor/status"
            monitor_response = requests.get(monitor_url, headers=headers, timeout=5)
            if monitor_response.status_code == 200:
                monitor_data = monitor_response.json()
                if monitor_data.get('success') and 'data' in monitor_data:
                    monitor_status = monitor_data['data']
        except:
            pass
        return {'server_healthy': server_healthy,'monitor_status': monitor_status,'timestamp': time.time()}
    except Exception as e:
        return {'server_healthy': False,'error': str(e),'timestamp': time.time()}

def check_task_details(task_id):
    try:
        status_url = f"http://127.0.0.1:5000/status/{task_id}"
        status_response = requests.get(status_url, timeout=10)
        result = {
            'task_id': task_id,
            'status_check_success': status_response.status_code == 200,
            'status_response': status_response.json() if status_response.status_code == 200 else status_response.text,
            'timestamp': time.time()
        }
        try:
            debug_url = f"http://127.0.0.1:5000/debug/{task_id}"
            debug_response = requests.get(debug_url, timeout=5)
            if debug_response.status_code == 200:
                result['debug_info'] = debug_response.json()
        except:
            pass
        return result
    except Exception as e:
        return {'task_id': task_id,'error': str(e),'timestamp': time.time()}

def submit_batch_tasks(pdb_file, sdf_files, target_name, headers, api_url, batch_size=4):
    submitted_tasks = []
    for i in range(0, len(sdf_files), batch_size):
        batch = sdf_files[i:i+batch_size]
        batch_tasks = []
        print(f"\n=== æäº¤æ‰¹æ¬¡ {i//batch_size + 1}/{(len(sdf_files) + batch_size - 1)//batch_size} ===")
        print(f"åŒ…å« {len(batch)} ä¸ªé…ä½“")
        for sdf_file in batch:
            ligand_name = os.path.basename(sdf_file).replace('.sdf', '')
            try:
                with open(pdb_file, 'rb') as pf, open(sdf_file, 'rb') as lf:
                    files = {
                        'protein_file': (os.path.basename(pdb_file), pf.read()),
                        'ligand_file': (os.path.basename(sdf_file), lf.read()),
                    }
                    data = {'ligand_resname': 'LIG','output_prefix': f"{target_name}_{ligand_name}",'priority': 'default'}
                    print(f"  æäº¤ä»»åŠ¡: {ligand_name}")
                    response = requests.post(api_url, headers=headers, files=files, data=data)
                    if response.status_code in [200, 202]:
                        response_data = response.json()
                        task_id = response_data.get('task_id')
                        if task_id:
                            task_info = {'task_id': task_id,'ligand_name': ligand_name,'sdf_file': sdf_file,'status': 'SUBMITTED','submit_time': time.time()}
                            batch_tasks.append(task_info)
                            print(f"    âœ“ ä»»åŠ¡å·²æäº¤: {task_id}")
                        else:
                            print(f"    âœ— æäº¤å¤±è´¥: æœªè¿”å›task_id")
                    else:
                        print(f"    âœ— æäº¤å¤±è´¥: {response.status_code} - {response.text}")
            except Exception as e:
                print(f"    âœ— æäº¤å¼‚å¸¸: {e}")
        if batch_tasks:
            submitted_tasks.extend(batch_tasks)
            print(f"  æ‰¹æ¬¡æäº¤å®Œæˆ: {len(batch_tasks)}/{len(batch)} ä¸ªä»»åŠ¡æˆåŠŸæäº¤")
            if i + batch_size < len(sdf_files):
                print(f"  ç­‰å¾…å½“å‰æ‰¹æ¬¡å®Œæˆåå†æäº¤ä¸‹ä¸€æ‰¹æ¬¡...")
                wait_for_batch_completion(batch_tasks)
        else:
            print(f"  æ‰¹æ¬¡æäº¤å¤±è´¥: 0/{len(batch)} ä¸ªä»»åŠ¡æˆåŠŸæäº¤")
    return submitted_tasks

def monitor_task_status(task_info):
    task_id = task_info['task_id']
    ligand_name = task_info['ligand_name']
    try:
        status_url = f"http://127.0.0.1:5000/status/{task_id}"
        response = requests.get(status_url, timeout=10)
        if response.status_code == 200:
            status_data = response.json()
            current_state = status_data.get('state', 'UNKNOWN')
            info = status_data.get('info', {})
            task_info['status'] = current_state
            task_info['last_check'] = time.time()
            task_info['raw_response'] = status_data
            if current_state == 'SUCCESS':
                task_info['completed'] = True
                task_info['success'] = True
            elif current_state in ['FAILURE','REVOKED']:
                task_info['completed'] = True
                task_info['success'] = False
                task_info['error_info'] = info
            elif current_state in ['PENDING','STARTED','PROGRESS']:
                task_info['completed'] = False
                if isinstance(info, dict):
                    if 'status' in info:
                        task_info['progress_info'] = info['status']
                        if "Running affinity prediction on GPU" in info['status']:
                            task_info['is_running_on_gpu'] = True
                            gpu_match = info['status'].split("GPU ")
                            if len(gpu_match) > 1:
                                task_info['gpu_id'] = gpu_match[1].strip()
                    if 'progress' in info:
                        task_info['progress_percent'] = info['progress']
                    if 'current_step' in info:
                        task_info['current_step'] = info['current_step']
                else:
                    task_info['progress_info'] = str(info) if info else "ä»»åŠ¡æ­£åœ¨å¤„ç†ä¸­..."
                if current_state == 'PROGRESS':
                    task_info['progress_description'] = "æ­£åœ¨GPUä¸Šæ‰§è¡Œäº²å’ŒåŠ›é¢„æµ‹" if task_info.get('is_running_on_gpu') else "ä»»åŠ¡æ­£åœ¨è¿›è¡Œä¸­"
                elif current_state == 'STARTED':
                    task_info['progress_description'] = "ä»»åŠ¡å·²å¼€å§‹æ‰§è¡Œ"
                elif current_state == 'PENDING':
                    submit_time = task_info.get('submit_time', time.time())
                    current_time = time.time()
                    if (current_time - submit_time) > 300:
                        task_info['progress_description'] = f"ä»»åŠ¡å·²æäº¤ {int((current_time - submit_time)/60)} åˆ†é’Ÿï¼Œå¯èƒ½æ­£åœ¨é˜Ÿåˆ—ä¸­"
                    else:
                        task_info['progress_description'] = "ä»»åŠ¡åœ¨é˜Ÿåˆ—ä¸­ç­‰å¾…"
            else:
                task_info['completed'] = False
                task_info['progress_info'] = f"ä»»åŠ¡çŠ¶æ€: {current_state}"
        else:
            task_info['status'] = 'ERROR'
            task_info['error_info'] = f"HTTP {response.status_code} - {response.text[:200]}"
    except Exception as e:
        task_info['status'] = 'ERROR'
        task_info['error_info'] = str(e)
    return task_info

def wait_for_batch_completion(batch_tasks, max_wait_time=7200, check_interval=30):
    print(f"\n--- ç›‘æ§ {len(batch_tasks)} ä¸ªä»»åŠ¡çš„æ‰§è¡ŒçŠ¶æ€ ---")
    start_time = time.time()
    completed_tasks = []
    consecutive_no_change_count = 0
    last_completed_count = 0
    task_id_map = {task['task_id']: task['ligand_name'] for task in batch_tasks}
    while time.time() - start_time < max_wait_time:
        active_tasks = [task for task in batch_tasks if not task.get('completed', False)]
        if not active_tasks:
            print("âœ“ æ‰€æœ‰ä»»åŠ¡å·²å®Œæˆ")
            break
        current_time = time.strftime('%H:%M:%S')
        elapsed_time = int(time.time() - start_time)
        print(f"\næ£€æŸ¥æ—¶é—´: {current_time} (å·²è¿è¡Œ {elapsed_time//60}:{elapsed_time%60:02d})")
        print(f"å‰©ä½™ä»»åŠ¡: {len(active_tasks)}")
        if len(active_tasks) <= 10:
            print(f"æ´»è·ƒä»»åŠ¡ID: {[task['task_id'][:8] + '...' for task in active_tasks]}")
        with ThreadPoolExecutor(max_workers=10) as executor:
            future_to_task = {executor.submit(monitor_task_status, task): task for task in active_tasks}
            status_changes = []
            for future in as_completed(future_to_task):
                task = future_to_task[future]
                try:
                    updated_task = future.result()
                    old_status = task.get('status', 'UNKNOWN')
                    new_status = updated_task.get('status', 'UNKNOWN')
                    if old_status != new_status:
                        status_changes.append(f"{task['ligand_name']}: {old_status} -> {new_status}")
                    task.update(updated_task)
                    if task.get('completed'):
                        if task.get('success'):
                            print(f"  âœ“ {task['ligand_name']}: ä»»åŠ¡å®Œæˆ")
                            completed_tasks.append(task)
                        else:
                            error_info = task.get('error_info', 'æœªçŸ¥é”™è¯¯')
                            print(f"  âœ— {task['ligand_name']}: ä»»åŠ¡å¤±è´¥ - {error_info}")
                            completed_tasks.append(task)
                    else:
                        status = task.get('status', 'UNKNOWN')
                        progress = task.get('progress_info', '')
                        progress_desc = task.get('progress_description', '')
                        gpu_info = f" (GPU {task.get('gpu_id')})" if task.get('gpu_id') else ""
                        if progress_desc:
                            print(f"  â³ {task['ligand_name']}: {progress_desc}{gpu_info}")
                        elif progress:
                            if "Running affinity prediction on GPU" in progress:
                                gpu_match = progress.split("GPU ")
                                gpu_num = gpu_match[1].strip() if len(gpu_match) > 1 else "?"
                                print(f"  ğŸ”¥ {task['ligand_name']}: æ­£åœ¨GPU {gpu_num}ä¸Šæ‰§è¡Œäº²å’ŒåŠ›é¢„æµ‹")
                            elif "Task is waiting in the queue" in progress:
                                submit_time = task.get('submit_time', time.time())
                                wait_time = int(time.time() - submit_time)
                                if wait_time > 600:
                                    print(f"  â° {task['ligand_name']}: å¯èƒ½æ­£åœ¨æ‰§è¡Œä¸­ (å·²ç­‰å¾… {wait_time//60} åˆ†é’Ÿ)")
                                else:
                                    print(f"  â° {task['ligand_name']}: é˜Ÿåˆ—ä¸­ç­‰å¾… ({wait_time//60}:{wait_time%60:02d})")
                            else:
                                print(f"  â³ {task['ligand_name']}: {progress}")
                        else:
                            if status == 'PROGRESS':
                                print(f"  ğŸ”„ {task['ligand_name']}: ä»»åŠ¡æ‰§è¡Œä¸­...")
                            elif status == 'STARTED':
                                print(f"  ğŸš€ {task['ligand_name']}: ä»»åŠ¡å·²å¯åŠ¨")
                            else:
                                print(f"  â³ {task['ligand_name']}: {status}")
                        if task.get('raw_response') and len(active_tasks) <= 5:
                            raw_info = task['raw_response'].get('info', {})
                            if isinstance(raw_info, dict) and raw_info:
                                debug_info = {k: v for k, v in raw_info.items() if k not in ['status']}
                                if debug_info:
                                    print(f"      è°ƒè¯•ä¿¡æ¯: {debug_info}")
                except Exception as e:
                    print(f"  âš ï¸  {task['ligand_name']}: çŠ¶æ€æ£€æŸ¥å¼‚å¸¸ - {e}")
        if status_changes:
            print(f"\nçŠ¶æ€å˜åŒ–:")
            for change in status_changes:
                print(f"  ğŸ“‹ {change}")
        completed_count = len([t for t in batch_tasks if t.get('completed', False)])
        success_count = len([t for t in batch_tasks if t.get('completed', False) and t.get('success', False)])
        print(f"è¿›åº¦: {completed_count}/{len(batch_tasks)} å®Œæˆ ({success_count} æˆåŠŸ)")
        if completed_count == last_completed_count:
            consecutive_no_change_count += 1
        else:
            consecutive_no_change_count = 0
            last_completed_count = completed_count
        if consecutive_no_change_count >= 5:
            total_wait_time = consecutive_no_change_count * check_interval
            print(f"âš ï¸  å·²è¿ç»­ {total_wait_time//60} åˆ†é’Ÿæ— ä»»åŠ¡å®Œæˆï¼Œæ£€æŸ¥ç³»ç»ŸçŠ¶æ€...")
            server_status = check_server_status()
            if not server_status['server_healthy']:
                print(f"âŒ æœåŠ¡å™¨çŠ¶æ€å¼‚å¸¸: {server_status.get('error', 'æœªçŸ¥é”™è¯¯')}")
            elif server_status.get('monitor_status'):
                print(f"ğŸ“Š æœåŠ¡å™¨ç›‘æ§çŠ¶æ€: {server_status['monitor_status']}")
            print("\nè¯¦ç»†ä»»åŠ¡çŠ¶æ€:")
            for task in active_tasks[:3]:
                task_info = task.get('raw_response', {})
                submit_time = task.get('submit_time', time.time())
                wait_time = int(time.time() - submit_time)
                print(f"  ä»»åŠ¡ {task['ligand_name']} ({task['task_id'][:8]}...):")
                print(f"    çŠ¶æ€: {task.get('status', 'UNKNOWN')}")
                print(f"    ç­‰å¾…æ—¶é—´: {wait_time//60}:{wait_time%60:02d}")
                print(f"    åŸå§‹ä¿¡æ¯: {task_info.get('info', {})}")
            if consecutive_no_change_count >= 10:
                print("\nğŸ” è¿›è¡Œæ·±åº¦ä»»åŠ¡æ£€æŸ¥...")
                for task in active_tasks[:2]:
                    detailed_info = check_task_details(task['task_id'])
                    print(f"  ä»»åŠ¡ {task['ligand_name']} è¯¦ç»†ä¿¡æ¯:")
                    print(f"    {detailed_info}")
                print("\nğŸš¨ å»ºè®®æ£€æŸ¥:")
                print("  1. APIæœåŠ¡å™¨æ˜¯å¦æ­£å¸¸è¿è¡Œ")
                print("  2. Celery workeræ˜¯å¦æ­£å¸¸å·¥ä½œ")
                print("  3. GPUèµ„æºæ˜¯å¦å¯ç”¨")
                print("  4. ä»»åŠ¡é˜Ÿåˆ—æ˜¯å¦æœ‰ç§¯å‹")
                print("  5. è¿è¡Œ 'ps aux | grep celery' æ£€æŸ¥workerè¿›ç¨‹")
                print("  6. æ£€æŸ¥ celery.log å’Œå…¶ä»–æ—¥å¿—æ–‡ä»¶")
        if completed_count < len(batch_tasks):
            print(f"ç­‰å¾… {check_interval} ç§’åç»§ç»­æ£€æŸ¥...")
            time.sleep(check_interval)
    final_completed = len([t for t in batch_tasks if t.get('completed', False)])
    if final_completed < len(batch_tasks):
        remaining_tasks = len(batch_tasks) - final_completed
        print(f"âš ï¸  ç­‰å¾…è¶…æ—¶ï¼Œä»æœ‰ {remaining_tasks} ä¸ªä»»åŠ¡æœªå®Œæˆ")
        incomplete_tasks = [t for t in batch_tasks if not t.get('completed', False)]
        print("æœªå®Œæˆçš„ä»»åŠ¡:")
        for task in incomplete_tasks:
            elapsed = int(time.time() - task.get('submit_time', time.time()))
            print(f"  - {task['ligand_name']} ({task['task_id'][:8]}...): {task.get('status', 'UNKNOWN')} (è¿è¡Œ {elapsed//60}:{elapsed%60:02d})")
    return completed_tasks

def download_and_parse_results(task_info, output_dir):
    """
    è¿”å›:
      {
        'task_id','ligand_name',
        'log_ic50': mean_affinity,   # API csv ä¸­ log10(uM)
        'ic50_uM': 10**mean_affinity,
        'pIC50_pred': 6 - mean_affinity,
        ...
      }
    """
    task_id = task_info['task_id']
    ligand_name = task_info['ligand_name']
    try:
        results_url = f"http://127.0.0.1:5000/results/{task_id}"
        response = requests.get(results_url, timeout=30)
        if response.status_code == 200:
            task_output_dir = os.path.join(output_dir, task_id)
            os.makedirs(task_output_dir, exist_ok=True)
            zip_path = os.path.join(task_output_dir, f"{task_id}_results.zip")
            with open(zip_path, 'wb') as f:
                f.write(response.content)
            results = {'task_id': task_id, 'ligand_name': ligand_name}
            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                zip_ref.extractall(task_output_dir)
                for root, dirs, files in os.walk(task_output_dir):
                    for file in files:
                        if file.endswith('.csv') and 'affinity' in file.lower():
                            csv_path = os.path.join(root, file)
                            try:
                                df = pd.read_csv(csv_path)
                                if not df.empty:
                                    row = df.iloc[0]
                                    affinity_cols = [c for c in df.columns if any(k in c.lower() for k in ['affinity_pred_value','ic50','binding'])]
                                    if affinity_cols:
                                        vals = []
                                        for c in affinity_cols:
                                            if pd.notna(row[c]):
                                                vals.append(float(row[c]))
                                        if vals:
                                            import numpy as np
                                            mean_affinity = float(np.mean(vals))  # è§†ä¸º log10(uM)
                                            std_affinity  = float(np.std(vals)) if len(vals) > 1 else 0.0
                                            ic50_uM = math.pow(10, mean_affinity)
                                            pIC50_pred = 6.0 - mean_affinity
                                            results.update({
                                                'log_ic50': mean_affinity,
                                                'ic50_uM': ic50_uM,
                                                'pIC50_pred': pIC50_pred,
                                                'affinity_std': std_affinity,
                                                'affinity_values': vals,
                                                'csv_file': csv_path
                                            })
                                            print(f"    âœ“ è§£æç»“æœ: IC50 = {ic50_uM:.3f} Î¼M (log10(uM) = {mean_affinity:.3f}, pIC50_pred = {pIC50_pred:.3f})")
                                            return results
                                print(f"    å¯ç”¨åˆ—: {list(df.columns)}")
                            except Exception as e:
                                print(f"    âœ— CSVè§£æå¤±è´¥: {e}")
                                continue
            print(f"    âš ï¸  æœªæ‰¾åˆ°æœ‰æ•ˆçš„äº²å’ŒåŠ›æ•°æ®")
            return results
        else:
            print(f"    âœ— ä¸‹è½½å¤±è´¥: HTTP {response.status_code}")
            return None
    except Exception as e:
        print(f"    âœ— ä¸‹è½½å¼‚å¸¸: {e}")
        return None

def split_sdf(sdf_file, output_dir):
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    with open(sdf_file, 'r') as f:
        sdf_content = f.read()
    molecules = sdf_content.split('$$$$')
    created_files = []
    for i, molecule in enumerate(molecules):
        if molecule.strip():
            mol_name = f"ligand_{i+1}"
            lines = molecule.strip().split('\n')
            if len(lines) > 0:
                mol_name = lines[0].strip()
            sanitized_mol_name = mol_name.replace('/', '_')
            output_filename = os.path.join(output_dir, f"{sanitized_mol_name}.sdf")
            with open(output_filename, 'w') as out_f:
                out_f.write(molecule.strip() + '\n$$$$')
            created_files.append(output_filename)
    return created_files

def get_target_directories(data_dir):
    return [os.path.join(data_dir, d) for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d)) and d != 'output']

def find_files(target_dir):
    pdb_file = None
    sdf_file = None
    for f in os.listdir(target_dir):
        if f.endswith('.pdb'):
            pdb_file = os.path.join(target_dir, f)
        elif f == 'ligands.sdf':
            sdf_file = os.path.join(target_dir, f)
    return pdb_file, sdf_file

def run_analysis():
    # --- API Configuration ---
    API_URL = "http://127.0.0.1:5000/api/affinity_separate"
    API_TOKEN = os.environ.get('API_SECRET_TOKEN')
    BATCH_SIZE = 4
    # -------------------------
    data_dir = '/data/Boltz-WebUI/affinity/data'
    output_base_dir = os.path.join(data_dir, 'output')
    results_output_dir = os.path.join(output_base_dir, 'api_results')
    if not API_TOKEN:
        print("é”™è¯¯: è¯·è®¾ç½® API_SECRET_TOKEN ç¯å¢ƒå˜é‡")
        return
    print("ğŸ” æ£€æŸ¥æœåŠ¡å™¨çŠ¶æ€...")
    server_status = check_server_status()
    if server_status['server_healthy']:
        print("âœ… æœåŠ¡å™¨çŠ¶æ€æ­£å¸¸")
        if server_status.get('monitor_status'):
            monitor_info = server_status['monitor_status']
            gpu_status = monitor_info.get('gpu_status', {})
            running_tasks = monitor_info.get('running_tasks', [])
            print(f"   ğŸ“Š GPUçŠ¶æ€: {gpu_status.get('in_use_count', 0)}/{gpu_status.get('in_use_count', 0) + gpu_status.get('available_count', 0)} æ­£åœ¨ä½¿ç”¨")
            if running_tasks:
                print(f"   ğŸ”¥ æ­£åœ¨è¿è¡Œ {len(running_tasks)} ä¸ªä»»åŠ¡:")
                for task in running_tasks[:3]:
                    gpu_id = task.get('gpu_id', '?')
                    running_time = task.get('running_time', 'unknown')
                    print(f"      GPU {gpu_id}: {task.get('task_id', '')[:8]}... (è¿è¡Œæ—¶é—´: {running_time})")
                if len(running_tasks) > 3:
                    print(f"      ... è¿˜æœ‰ {len(running_tasks) - 3} ä¸ªä»»åŠ¡")
            print(f"   â° æ£€æŸ¥æ—¶é—´: {time.strftime('%H:%M:%S')}")
    else:
        print(f"âŒ æœåŠ¡å™¨çŠ¶æ€å¼‚å¸¸: {server_status.get('error', 'æœªçŸ¥é”™è¯¯')}")
        print("è¯·æ£€æŸ¥APIæœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œ")
        return
    print("ğŸ”§ è¿è¡Œé…ç½®:")
    print(f"   API URL: {API_URL}")
    print(f"   æ‰¹å¤„ç†å¤§å°: {BATCH_SIZE}")
    print(f"   æ•°æ®ç›®å½•: {data_dir}")
    print(f"   è¾“å‡ºç›®å½•: {results_output_dir}")
    print(f"   API Token: {'å·²è®¾ç½®' if API_TOKEN else 'æœªè®¾ç½®'}")
    headers = {"X-API-Token": API_TOKEN}
    target_dirs = get_target_directories(data_dir)
    print(f"å‘ç° {len(target_dirs)} ä¸ªç›®æ ‡ç›®å½•")
    print(f"æ‰¹å¤„ç†å¤§å°: {BATCH_SIZE}")
    print("=" * 60)

    for target_dir in target_dirs:
        target_name = os.path.basename(target_dir)
        print(f"\nğŸ¯ å¤„ç†ç›®æ ‡: {target_name}")
        pdb_file, ligands_sdf = find_files(target_dir)
        if not pdb_file or not ligands_sdf:
            print(f"  âš ï¸  è·³è¿‡ {target_name}: æœªæ‰¾åˆ° PDB æˆ– ligands.sdf æ–‡ä»¶")
            continue

        # å…ˆè§£æ SDF å¾—åˆ°å®éªŒ pIC50 æ˜ å°„
        print("  ğŸ§ª è§£æ ligands.sdf å®éªŒå€¼ ...")
        exp_map = load_sdf_pIC50_map(ligands_sdf)
        n_exp = sum(1 for v in exp_map.values() if v.get('pIC50_exp') is not None)
        print(f"  âœ… ä» SDF è¯»å–åˆ° {n_exp} ä¸ªå¯ç”¨çš„å®éªŒ pIC50 / {len(exp_map)}")

        split_sdf_dir = os.path.join(output_base_dir, target_name, 'split_sdfs')
        individual_sdf_files = split_sdf(ligands_sdf, split_sdf_dir)
        print(f"  å‘ç° {len(individual_sdf_files)} ä¸ªé…ä½“åˆ†å­")

        # FEP+ ç»“æœå˜ä¸ºå¯é€‰ï¼Œä¸ä¸­æ–­æµç¨‹
        fep_results_file = os.path.join(target_dir, 'results_20ns.csv')
        if not os.path.exists(fep_results_file):
            fep_results_file = os.path.join(target_dir, 'results_5ns.csv')
        fep_df = None
        if os.path.exists(fep_results_file):
            try:
                fep_df = pd.read_csv(fep_results_file)
                # å¤„ç†é…ä½“åç§°ï¼Œå»æ‰ ".0" åç¼€ä»¥åŒ¹é… SDF ä¸­çš„åç§°
                fep_df['Ligand'] = fep_df['Ligand'].astype(str).str.replace('.0','',regex=False)
                print(f"  ï¼ˆå¯é€‰ï¼‰åŠ è½½ FEP+ ç»“æœ: {len(fep_df)} è¡Œ")
            except Exception as e:
                print(f"  âš ï¸ FEP+ æ–‡ä»¶è¯»å–å¤±è´¥ï¼š{e}")

        # æäº¤ä»»åŠ¡
        print(f"\nğŸš€ å¼€å§‹æ‰¹é‡æäº¤ä»»åŠ¡...")
        all_tasks = submit_batch_tasks(
            pdb_file, individual_sdf_files, target_name,
            headers, API_URL, BATCH_SIZE
        )
        if not all_tasks:
            print(f"  âŒ æ²¡æœ‰æˆåŠŸæäº¤ä»»ä½•ä»»åŠ¡")
            continue

        print(f"\nğŸ“Š å¤„ç†ç»“æœå¹¶ç”Ÿæˆ pIC50 æ¯”è¾ƒ...")
        comparison_rows = []
        for task in all_tasks:
            if task.get('completed') and task.get('success'):
                print(f"\n  ğŸ“¥ ä¸‹è½½ç»“æœ: {task['ligand_name']}")
                result_data = download_and_parse_results(task, results_output_dir)
                if result_data and ('pIC50_pred' in result_data):
                    ligand_name = task['ligand_name']
                    # é¢„æµ‹
                    pIC50_pred = result_data['pIC50_pred']
                    ic50_uM_pred = result_data.get('ic50_uM')
                    # å®éªŒï¼ˆæ¥è‡ª SDFï¼‰
                    exp_info = exp_map.get(ligand_name, {})
                    pIC50_exp = exp_info.get('pIC50_exp')
                    exp_raw = exp_info.get('exp_raw')
                    exp_field = exp_info.get('exp_field')
                    exp_unit = exp_info.get('exp_unit')

                    if pIC50_exp is None:
                        print(f"      âš ï¸  {ligand_name} åœ¨ SDF ä¸­æœªæ‰¾åˆ°å¯ç”¨å®éªŒå€¼ï¼Œå°†ä¿ç•™ç©ºå€¼")

                    row = {
                        'Target': target_name,
                        'Ligand': ligand_name,
                        'pIC50_pred': pIC50_pred,
                        'IC50_uM_pred': ic50_uM_pred,
                        'pIC50_exp': pIC50_exp,
                        'Exp_raw_in_SDF': exp_raw,
                        'Exp_field_in_SDF': exp_field,
                        'Exp_unit_inferred': exp_unit,
                        'Task_ID': task['task_id']
                    }

                    # è‹¥å­˜åœ¨ FEPï¼Œå¯é™„å¸¦å¹¶è½¬æ¢ä¸º pIC50
                    if fep_df is not None and 'Ligand' in fep_df.columns:
                        _row = fep_df[fep_df['Ligand'] == ligand_name]
                        if not _row.empty:
                            for c in ['Pred. Binding (Î”G)','Exp. Binding (Î”G)','Pred. Î”G','Exp. Î”G']:
                                if c in _row.columns:
                                    original_dg = _row.iloc[0][c]
                                    row[f'FEP_{c}'] = original_dg
                                    # è½¬æ¢ä¸º pIC50
                                    if 'Pred' in c:
                                        pIC50_fep = delta_g_to_pIC50(original_dg)
                                        if pIC50_fep is not None:
                                            row['FEP_pIC50_pred'] = pIC50_fep
                                    elif 'Exp' in c:
                                        pIC50_fep = delta_g_to_pIC50(original_dg)
                                        if pIC50_fep is not None:
                                            row['FEP_pIC50_exp'] = pIC50_fep

                    comparison_rows.append(row)
                    # å‹å¥½æ‰“å°
                    if pIC50_exp is not None:
                        print(f"      pIC50_pred = {pIC50_pred:.3f} | pIC50_exp = {pIC50_exp:.3f} | Î” = {pIC50_pred - pIC50_exp:+.3f}")
                    else:
                        print(f"      pIC50_pred = {pIC50_pred:.3f} | pIC50_exp = NA")
                else:
                    print(f"      âŒ æ— æ³•è§£æ {task['ligand_name']} çš„é¢„æµ‹ç»“æœ")
            else:
                print(f"  âŒ ä»»åŠ¡å¤±è´¥: {task['ligand_name']} - {task.get('error_info', 'æœªçŸ¥é”™è¯¯')}")

        # ä¿å­˜å¯¹æ¯”ç»“æœ
        if comparison_rows:
            comparison_df = pd.DataFrame(comparison_rows)
            os.makedirs(results_output_dir, exist_ok=True)
            output_csv = os.path.join(results_output_dir, f"{target_name}_pIC50_comparison.csv")
            comparison_df.to_csv(output_csv, index=False)

            print(f"\nğŸ“ˆ {target_name} å¤„ç†å®Œæˆ:")
            print(f"    æˆåŠŸé¢„æµ‹: {len(comparison_rows)}/{len(individual_sdf_files)} ä¸ªé…ä½“")
            print(f"    pIC50 å¯¹æ¯”ç»“æœä¿å­˜è‡³: {output_csv}")

            # è¯¯å·®ç»Ÿè®¡ï¼ˆä»…å¯¹åŒæ—¶æœ‰å®éªŒä¸é¢„æµ‹çš„è¡Œï¼‰
            mask = comparison_df['pIC50_exp'].notna() & comparison_df['pIC50_pred'].notna()
            if mask.any():
                diffs = (comparison_df.loc[mask, 'pIC50_pred'] - comparison_df.loc[mask, 'pIC50_exp']).abs()
                mae = diffs.mean()
                std = diffs.std()
                print(f"    |pIC50_pred - pIC50_exp|: MAE = {mae:.3f} Â± {std:.3f} (n={mask.sum()})")
            else:
                print("    âš ï¸ æ— å¯ç”¨äº MAE çš„é…å¯¹æ ·æœ¬ï¼ˆç¼ºå°‘å®éªŒæˆ–é¢„æµ‹ pIC50ï¼‰")
        else:
            print(f"  âŒ {target_name}: æ²¡æœ‰æˆåŠŸçš„é¢„æµ‹ç»“æœ")

        print("=" * 60)

    print("\nğŸ‰ æ‰€æœ‰ç›®æ ‡å¤„ç†å®Œæˆï¼")

if __name__ == '__main__':
    run_analysis()
